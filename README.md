# Docker â€“ Guide Complet pour DÃ©butants

## 1. Introduction Ã  Docker

Docker est une plateforme logicielle qui utilise la **conteneurisation** pour exÃ©cuter des applications dans des environnements isolÃ©s appelÃ©s *conteneurs*. Un conteneur embarque une application ainsi que toutes ses dÃ©pendances (bibliothÃ¨ques, configuration, etc.) afin quâ€™elle puisse tourner de maniÃ¨re uniforme sur tout systÃ¨me supportant Docker ([Docker, c'est quoi ?](https://www.redhat.com/fr/topics/containers/what-is-docker#:~:text=Voici%20les%20diff%C3%A9rentes%20d%C3%A9finitions%C2%A0%3A)). En sâ€™appuyant sur des fonctionnalitÃ©s du noyau Linux (telles que les *cgroups* et les *namespaces*), Docker parvient Ã  isoler les processus tout en consommant peu de ressources ([Docker, c'est quoi ?](https://www.redhat.com/fr/topics/containers/what-is-docker#:~:text=La%20technologie%20Docker%20utilise%20le,que%20celui%20des%20syst%C3%A8mes%20distincts)). On obtient ainsi un niveau dâ€™isolation suffisant pour exÃ©cuter plusieurs applications sur la mÃªme machine en toute sÃ©curitÃ©, sans conflits de dÃ©pendances, et avec une empreinte beaucoup plus lÃ©gÃ¨re quâ€™avec la virtualisation traditionnelle.

**Avantages de Docker :** la conteneurisation avec Docker prÃ©sente de nombreux atouts : 

- **PortabilitÃ©** â€“ Un conteneur Docker peut Ãªtre exÃ©cutÃ© sur nâ€™importe quel systÃ¨me disposant de Docker (Linux, Windows, macOS). Cela garantit que lâ€™application fonctionne de la mÃªme maniÃ¨re en dÃ©veloppement, en test ou en production.
- **LÃ©gÃ¨retÃ© et rapiditÃ©** â€“ Les conteneurs sont trÃ¨s lÃ©gers comparÃ©s aux machines virtuelles car ils partagent le noyau de lâ€™OS hÃ´te. Ils se lancent en quelques secondes (voire moins) et consomment peu de RAM et de CPU, ce qui permet dâ€™en exÃ©cuter un grand nombre sur une machine donnÃ©e ([Docker, c'est quoi ?](https://www.redhat.com/fr/topics/containers/what-is-docker#:~:text=)).
- **Isolation** â€“ Chaque conteneur sâ€™exÃ©cute de faÃ§on isolÃ©e, avec son propre systÃ¨me de fichiers, ses variables dâ€™environnement et ses ports. Cela Ã©vite les conflits entre applications et amÃ©liore la sÃ©curitÃ© (un problÃ¨me dans un conteneur nâ€™affecte pas les autres).
- **ScalabilitÃ©** â€“ GrÃ¢ce Ã  leur dÃ©marrage rapide et leur faible overhead, il est facile de crÃ©er ou supprimer des conteneurs Ã  la volÃ©e pour adapter la charge (montÃ©e en charge horizontale). Docker sâ€™intÃ¨gre bien avec des outils dâ€™orchestration (comme Kubernetes) qui automatisent cette scalabilitÃ©.
- **ReproductibilitÃ©** â€“ Docker permet de dÃ©finir lâ€™environnement dâ€™une application dans un fichier de configuration (Dockerfile). Cela assure que chaque dÃ©veloppeur ou serveur utilise le mÃªme environnement, Ã©liminant le classique Â« *Ã§a marche sur ma machine* Â».

Un conteneur peut Ãªtre comparÃ© Ã  une machine virtuelle trÃ¨s minimaliste. Pour bien comprendre, examinons les diffÃ©rences entre conteneurs Docker et machines virtuelles (VM) classiques :

| **CaractÃ©ristique**         | **Machine Virtuelle (VM)**                                               | **Conteneur Docker**                                           |
|----------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------|
| **Isolation**              | Isolation complÃ¨te incluant un OS invitÃ© sÃ©parÃ©. TrÃ¨s sÃ»r, le VM est entiÃ¨rement sandboxÃ© du systÃ¨me hÃ´te. | Isolation au niveau du systÃ¨me dâ€™exploitation hÃ´te (partage du mÃªme noyau). Moins hermÃ©tique quâ€™une VM, mais suffisamment cloisonnÃ© pour la plupart des usages ([Docker, c'est quoi ?](https://www.redhat.com/fr/topics/containers/what-is-docker#:~:text=une%20br%C3%A8che%20de%20s%C3%A9curit%C3%A9,mieux%20isol%C3%A9es%20du%20syst%C3%A8me%20h%C3%B4te)). |
| **SystÃ¨me dâ€™exploitation** | Chaque VM embarque son propre OS complet (kernel + userland). Consomme davantage de CPU, RAM, stockage. | Ne contient que lâ€™application et ses dÃ©pendances au-dessus du noyau de lâ€™OS hÃ´te. Pas de kernel invitÃ© -> empreinte rÃ©duite. |
| **DÃ©marrage**              | Lancement en minutes : il faut booter un OS entier.                      | Lancement en quelques secondes : le processus de lâ€™application dÃ©marre directement, le kernel Ã©tant dÃ©jÃ  lÃ . |
| **PortabilitÃ©**            | Images lourdes (plusieurs Go) spÃ©cifiques Ã  un hyperviseur, moins faciles Ã  dÃ©placer. | Images lÃ©gÃ¨res (quelques dizaines ou centaines de Mo) partageables via des registres (Docker Hub, etc.), faciles Ã  transfÃ©rer. |
| **CompatibilitÃ© OS**       | Peut exÃ©cuter un OS invitÃ© diffÃ©rent de lâ€™hÃ´te (ex: une VM Windows sur un Linux). | Doit utiliser le mÃªme type de noyau que lâ€™hÃ´te (ex: conteneurs Linux sur un hÃ´te Linux). Pas de noyau Windows sur un Docker Linux (sauf via VM). |
| **Performances**           | Overhead important dÃ» Ã  la virtualisation du matÃ©riel complet.           | Overhead minime : performances proches de lâ€™exÃ©cution native, grÃ¢ce Ã  lâ€™utilisation directe du kernel de lâ€™hÃ´te. |

En rÃ©sumÃ©, Docker ne *virtualise* pas du matÃ©riel comme le fait une VM ; il *isole* des processus au-dessus du systÃ¨me hÃ´te. Cela explique quâ€™un conteneur soit beaucoup plus lÃ©ger en ressources quâ€™une VM tout en restant suffisamment isolÃ© pour la plupart des applications. GrÃ¢ce Ã  Docker, on obtient Â« des machines virtuelles trÃ¨s lÃ©gÃ¨res et modulaires Â» faciles Ã  crÃ©er, dÃ©ployer, copier et dÃ©placer dâ€™un environnement Ã  un autre ([Docker, c'est quoi ?](https://www.redhat.com/fr/topics/containers/what-is-docker#:~:text=Gr%C3%A2ce%20%C3%A0%20Docker%2C%20les%20conteneurs,ainsi%20optimis%C3%A9es%20pour%20le%20cloud)).

Docker a rÃ©volutionnÃ© les workflows de dÃ©veloppement et de dÃ©ploiement. Il sâ€™est imposÃ© comme un outil incontournable du mouvement DevOps, permettant aux dÃ©veloppeurs et aux administrateurs systÃ¨me de collaborer plus efficacement. En dÃ©veloppant votre application dans un conteneur, vous pouvez garantir quâ€™elle fonctionnera de faÃ§on identique chez tous les membres de lâ€™Ã©quipe et en production. Dans les chapitres suivants, nous allons dÃ©couvrir comment installer Docker, lâ€™utiliser pas Ã  pas, construire nos propres images, et enfin orchestrer des conteneurs en production.

## 2. Installation de Docker

Docker peut sâ€™installer sur la plupart des environnements : distributions Linux, Windows 10/11 et macOS. Les Ã©tapes dâ€™installation varient selon le systÃ¨me dâ€™exploitation. Nous dÃ©taillons ci-dessous la procÃ©dure pour Linux, Windows et macOS.

### 2.1 Sur Linux (Ubuntu/Debian)

Nous prenons ici lâ€™exemple dâ€™Ubuntu (les Ã©tapes sont similaires pour Debian). Lâ€™installation se fait via la ligne de commandeÂ :

1. **DÃ©sinstaller dâ€™anciennes versions (le cas Ã©chÃ©ant)** â€“ Si Docker Ã©tait dÃ©jÃ  installÃ© via les dÃ©pÃ´ts officiels dâ€™Ubuntu sous le nom `docker.io` ou une ancienne version *Docker*/*Docker Engine*, il est recommandÃ© de la supprimer pour Ã©viter les conflits :  
   ```bash
   sudo apt remove docker docker-engine docker.io containerd runc
   ```
   (Cette commande ignore les packages non installÃ©s.)

2. **Installer les prÃ©requis** â€“ Mettez Ã  jour lâ€™index APT et installez les paquets permettant dâ€™utiliser un repository via HTTPS :  
   ```bash
   sudo apt update
   sudo apt install -y ca-certificates curl gnupg lsb-release
   ```
   Ces paquets servent Ã  ajouter la clÃ© GPG de Docker et le dÃ©pÃ´t officiel.

3. **Ajouter le dÃ©pÃ´t officiel Docker** â€“ Ajoutez la clÃ© GPG officielle de Docker, puis le dÃ©pÃ´t stable Ã  vos sources APT :  
   ```bash
   sudo mkdir -p /etc/apt/keyrings
   curl -fsSL https://download.docker.com/linux/ubuntu/gpg \
       | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
   echo \
     "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
     https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" \
     | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
   ```  
   Cette commande configure le dÃ©pÃ´t Docker pour votre distribution (la variable `$(lsb_release -cs)` insÃ¨re le nom de code dâ€™Ubuntu, par ex. *focal*, *jammy*...).

4. **Installer Docker Engine** â€“ Mettez Ã  jour lâ€™index des paquets puis installez Docker et Containerd (son runtime conteneur) :  
   ```bash
   sudo apt update
   sudo apt install -y docker-ce docker-ce-cli containerd.io
   ```  
   AprÃ¨s lâ€™installation, le service Docker (daemon) dÃ©marre automatiquement. Vous pouvez vÃ©rifier son statut par `sudo systemctl status docker`.

5. **Post-installation (optionnel)** â€“ Par dÃ©faut, la commande `docker` doit Ãªtre exÃ©cutÃ©e avec les droits *root* (ou via `sudo`). Pour permettre Ã  votre utilisateur de lancer Docker sans `sudo`, ajoutez-le au groupe `docker` :  
   ```bash
   sudo usermod -aG docker $USER
   ```  
   **Note:** Il faudra vous dÃ©connecter/reconnecter (ou lancer un nouveau shell) pour que ce changement prenne effet. Ensuite, la commande `docker info` devrait fonctionner sans `sudo`.

6. **Tester lâ€™installation** â€“ Lancez le conteneur de test officiel :  
   ```bash
   docker run hello-world
   ```  
   Ce conteneur dâ€™exemple affiche un message de bienvenue, confirmant que Docker fonctionne correctement. Sâ€™il sâ€™exÃ©cute sans erreur, Docker est bien installÃ© sur votre systÃ¨me.

### 2.2 Sur Windows 10/11

Sous Windows, Docker sâ€™exÃ©cute via **Docker Desktop**, une application fournissant le moteur Docker dans une machine virtuelle lÃ©gÃ¨re (basÃ©e sur Hyper-V ou WSL2). Voici comment lâ€™installer :

1. **VÃ©rifier les prÃ©requis** â€“ Docker Desktop requiert Windows 10/11 64-bit. Sur Windows 10 Home/Pro, assurez-vous dâ€™avoir la fonctionnalitÃ© Windows Subsystem for Linux 2 (**WSL2**) activÃ©e (Docker lâ€™utilise pour faire tourner Docker Engine). Activez Ã©galement la **virtualisation** dans le BIOS de votre PC si ce nâ€™est pas dÃ©jÃ  le cas.
2. **TÃ©lÃ©charger Docker Desktop** â€“ Rendez-vous sur le site officiel de Docker et tÃ©lÃ©chargez lâ€™installeur Docker Desktop pour Windows (un fichier `.exe`).
3. **Installer Docker Desktop** â€“ ExÃ©cutez lâ€™installeur. Cochez lâ€™option dâ€™utilisation de WSL2 si proposÃ©e. Lâ€™installation va configurer Docker et WSL2 automatiquement. Un redÃ©marrage peut Ãªtre demandÃ©.
4. **Lancer Docker** â€“ AprÃ¨s installation, lancez **Docker Desktop** depuis le menu DÃ©marrer. Attendez que Docker dÃ©marre (lâ€™icÃ´ne Docker dans la zone de notification deviendra stable ou affichera Â« Docker is running Â»).
5. **Tester avec un conteneur** â€“ Ouvrez un terminal PowerShell ou lâ€™invite de commandes (CMD) et exÃ©cutez :  
   ```powershell
   docker run hello-world
   ```  
   Vous devriez voir le message de bienvenue de Docker, comme sous Linux. Docker est opÃ©rationnel sur votre machine Windows. (En arriÃ¨re-plan, Docker utilise une VM Linux via WSL2 pour exÃ©cuter ce conteneur Linux.)

*Remarques Windows :* Docker Desktop intÃ¨gre une interface utilisateur pour configurer des paramÃ¨tres (par ex. la quantitÃ© de mÃ©moire/CPU allouÃ©e Ã  Docker, le choix entre backend WSL2 ou Hyper-V, etc.). Docker Desktop permet Ã©galement dâ€™exÃ©cuter des conteneurs Windows natifs si nÃ©cessaire, mais par dÃ©faut, câ€™est le mode conteneurs Linux qui est utilisÃ©, car câ€™est le plus courant.

### 2.3 Sur macOS

Sous macOS, Docker sâ€™installe Ã©galement via Docker Desktop :

1. **TÃ©lÃ©charger Docker Desktop** â€“ Depuis le site officiel Docker, tÃ©lÃ©chargez lâ€™image disque **Docker Desktop for Mac** (`.dmg`) compatible avec votre version de macOS (Intel ou Apple Silicon).
2. **Installer lâ€™application** â€“ Ouvrez le fichier `.dmg` puis faites glisser lâ€™icÃ´ne Docker dans le dossier Applications.
3. **Lancer Docker** â€“ Ouvrez Docker Desktop (via Spotlight ou Applications). Au premier lancement, macOS vous demandera dâ€™autoriser Docker Ã  avoir les privilÃ¨ges administrateur pour installer ses composants (Docker utilise en interne lâ€™hyperviseur macOS pour crÃ©er une VM Linux). Acceptez et entrez votre mot de passe si requis.
4. **VÃ©rifier le dÃ©marrage** â€“ Patientez quelques instants le temps que Docker dÃ©marre en arriÃ¨re-plan. Vous devriez voir lâ€™indicateur Â« Docker is running Â» dans la barre de menus (une icÃ´ne de baleine).
5. **Tester un conteneur** â€“ Ouvrez lâ€™application Terminal et lancez :  
   ```bash
   docker run hello-world
   ```  
   Si le message de bienvenue sâ€™affiche, lâ€™installation est un succÃ¨s.

*Remarques macOS :* Comme sur Windows, Docker Desktop sur Mac gÃ¨re une VM Linux lÃ©gÃ¨re en coulisses (via *hyperkit* ou le framework de virtualisation Apple) pour exÃ©cuter Docker Engine. Vous pouvez ajuster dans les prÃ©fÃ©rences la RAM/CPU allouÃ©s Ã  Docker. Lâ€™utilisation de Docker sur Mac ou Windows est quasiment identique Ã  Linux du point de vue des commandes (une fois Docker Desktop en fonctionnement). 

## 3. Premiers pas avec Docker

Maintenant que Docker est installÃ©, explorons les bases de son utilisation. Nous allons apprendre Ã  exÃ©cuter notre premier conteneur, Ã  gÃ©rer les **images Docker** locales, et Ã  utiliser les commandes courantes de Docker.

### 3.1 ExÃ©cuter un premier conteneur

La commande de base pour lancer un conteneur est `docker run`. Par exemple, exÃ©cutons un conteneur simple qui affiche un message puis sâ€™arrÃªteÂ :

```bash
docker run hello-world
```

Docker va rechercher lâ€™image nommÃ©e **hello-world** en local. Si elle nâ€™est pas trouvÃ©e, il la tÃ©lÃ©chargera automatiquement depuis Docker Hub (le registre public par dÃ©faut). Une fois lâ€™image rÃ©cupÃ©rÃ©e, Docker crÃ©e un conteneur et exÃ©cute le programme Ã  lâ€™intÃ©rieur. Dans ce cas, le conteneur affiche un message de bienvenue puis se termine. Vous verrez dans la console le texte "Hello from Docker!" confirmant le bon fonctionnement de Docker.

Maintenant, lanÃ§ons un conteneur plus utile, par exemple un serveur web Nginx. Nous utiliserons lâ€™option `-d` (dÃ©tachÃ©) pour lancer le conteneur en arriÃ¨re-plan, et `-p 8080:80` pour publier le port 80 du conteneur sur le port 8080 de notre machine :

```bash
docker run -d -p 8080:80 --name monserveur nginx:latest
```

Cette commande tÃ©lÃ©charge lâ€™image **nginx:latest** (si pas dÃ©jÃ  prÃ©sente), puis dÃ©marre un conteneur nommÃ© *monserveur* exÃ©cutant Nginx en arriÃ¨re-plan. Le serveur web Ã  lâ€™intÃ©rieur Ã©coute sur le port 80 du conteneur, que nous avons mappÃ© sur le port 8080 de lâ€™hÃ´te. Cela signifie quâ€™on peut ouvrir un navigateur et accÃ©der Ã  `http://localhost:8080` pour voir la page par dÃ©faut dâ€™Nginx. 

On peut vÃ©rifier que le conteneur tourne bien via la commande `docker ps` (nous verrons cette commande en dÃ©tail dans la section suivante). Si besoin, on peut consulter les logs du conteneur Nginx avec `docker logs monserveur`. Pour arrÃªter le conteneur, utilisez `docker stop monserveur` (ce qui envoie un signal dâ€™arrÃªt au processus Nginx). Vous pouvez ensuite le redÃ©marrer avec `docker start monserveur` si nÃ©cessaire.

> ğŸ”¹ **Astuce :** La premiÃ¨re fois que vous lancez une image Docker, le tÃ©lÃ©chargement peut prendre du temps (dÃ©pendant de la taille de lâ€™image et de votre connexion). Les exÃ©cutions suivantes seront instantanÃ©es si lâ€™image est dÃ©jÃ  prÃ©sente localement.

### 3.2 Gestion des images Docker

Une **image Docker** est un gabarit (template) Ã  partir duquel les conteneurs sont lancÃ©s. On peut voir une image comme une Â« classe Â», et un conteneur comme une Â« instance Â» de cette classe. Docker fournit des centaines dâ€™images officielles sur Docker Hub (par exemple nginx, mysql, ubuntu, node, etc.), et vous pouvez aussi construire vos propres images (voir chapitre 4).

Quelques commandes utiles pour gÃ©rer les images en local :

- `docker images` : liste les images prÃ©sentes sur votre machine (nom, tag, identifiant, taille, etc.).
- `docker pull <image>` : tÃ©lÃ©charge une image depuis Docker Hub sans la lancer. Par exemple, `docker pull ubuntu:20.04` rÃ©cupÃ¨re lâ€™image Ubuntu 20.04.
- `docker rmi <image>` : supprime une image locale (si plus aucun conteneur ne lâ€™utilise). Utile pour faire du mÃ©nage et Ã©conomiser de lâ€™espace disque.
- `docker search <mot-clÃ©>` : permet de rechercher des images sur Docker Hub en fonction dâ€™un mot-clÃ© (ex: `docker search redis`).

Lorsque nous avons lancÃ© `docker run hello-world`, Docker a fait implicitement un `pull` de lâ€™image *hello-world*. De mÃªme, `docker run nginx` va automatiquement tÃ©lÃ©charger lâ€™image *nginx:latest* si vous ne lâ€™avez pas dÃ©jÃ . Vous pouvez bien sÃ»r spÃ©cifier une version particuliÃ¨re dâ€™une image en ajoutant un **tag** aprÃ¨s le nom (format `nom:tag`). Par dÃ©faut, si aucun tag nâ€™est prÃ©cisÃ©, Docker utilise le tag `latest` (souvent le dernier build stable). Par exemple, `docker run alpine:3.16` lancera Alpine Linux v3.16, tandis que `docker run alpine` Ã©quivaut Ã  `alpine:latest` (la version alpine la plus rÃ©cente).

Pour voir un aperÃ§u des images sur votre systÃ¨me, exÃ©cutez `docker images`. Essayez par exemple aprÃ¨s avoir lancÃ© quelques conteneurs de test :

```bash
$ docker images
REPOSITORY   TAG       IMAGE ID       CREATED       SIZE
nginx        latest    <image-id>     2 weeks ago   142MB
ubuntu       20.04     <image-id>     3 weeks ago   72.8MB
hello-world  latest    <image-id>     5 months ago  13kB
```

On voit le nom du dÃ©pÃ´t (repository), le tag, lâ€™ID unique de lâ€™image, la date de crÃ©ation et la taille. Ici nous avons trois images : nginx, ubuntu:20.04, et hello-world.

### 3.3 Commandes Docker de base

Docker propose de nombreuses commandes pour examiner et manipuler les conteneurs et images. Voici un tableau rÃ©capitulatif des commandes de base que tout dÃ©butant doit connaÃ®tre :

| **Commande**                    | **Description**                                                |
|---------------------------------|----------------------------------------------------------------|
| `docker run <image>`            | TÃ©lÃ©charge (si besoin) lâ€™image spÃ©cifiÃ©e et crÃ©e un nouveau conteneur Ã  partir de celle-ci, puis lâ€™exÃ©cute. Des options peuvent Ãªtre ajoutÃ©es (voir exemples prÃ©cÃ©dents). |
| `docker ps`                     | Liste les conteneurs *en cours dâ€™exÃ©cution*. Ajoutez `-a` (`docker ps -a`) pour lister *tous* les conteneurs, y compris arrÃªtÃ©s. |
| `docker stop <nom ou id>`          | ArrÃªte un conteneur (en envoyant un signal SIGTERM puis SIGKILL si nÃ©cessaire aprÃ¨s dÃ©lai). |
| `docker start <nom ou id>`         | DÃ©marre un conteneur qui Ã©tait arrÃªtÃ© (ne fonctionne pas sur un conteneur dÃ©jÃ  supprimÃ©). |
| `docker restart <nom ou id>`       | RedÃ©marre un conteneur (Ã©quivalent Ã  un stop suivi dâ€™un start). |
| `docker rm <nom ou id>`            | Supprime un conteneur arrÃªtÃ© (supprime ses ressources). Ajoutez `-f` pour forcer la suppression dâ€™un conteneur mÃªme sâ€™il est en cours dâ€™exÃ©cution (Docker effectuera alors un stop forcÃ©). |
| `docker logs <nom ou id>`          | Affiche les logs (stdout/stderr) dâ€™un conteneur. Utile pour vÃ©rifier le output dâ€™une application tournant en arriÃ¨re-plan. Ajoutez `-f` pour *follower* les logs en continu. |
| `docker exec -it <cont> <cmd>`  | ExÃ©cute une commande Ã  lâ€™intÃ©rieur dâ€™un conteneur en cours dâ€™exÃ©cution. Par exemple `docker exec -it monserveur /bin/bash` ouvre un shell Bash interactif dans le conteneur *monserveur*. TrÃ¨s pratique pour du dÃ©bogage. |
| `docker inspect <nom ou id>`       | Fournit en sortie JSON tous les dÃ©tails sur un conteneur ou une image (configuration, rÃ©seaux, volumes, variables dâ€™env, etc.). |

Avec ces commandes de base, vous pouvez dÃ©jÃ  piloter lâ€™essentiel de Docker : lancer et arrÃªter des applications conteneurisÃ©es, surveiller leurs logs, et gÃ©rer les images. Au fil des chapitres, nous introduirons dâ€™autres commandes plus spÃ©cifiques (par exemple pour les volumes, les rÃ©seaux, etc.). Nâ€™hÃ©sitez pas Ã  utiliser `docker --help` ou la documentation en ligne pour approfondir chaque commande.

## 4. Dockerfile et construction dâ€™images

Jusquâ€™Ã  prÃ©sent, nous avons utilisÃ© des images existantes (issues de Docker Hub). Lâ€™un des grands pouvoirs de Docker est de permettre de **construire vos propres images** pour y empaqueter *votre* application. Pour cela, on Ã©crit un fichier texte appelÃ© **Dockerfile** qui contient les instructions de construction de lâ€™image. Dans cette section, nous allons dÃ©couvrir la syntaxe dâ€™un Dockerfile, construire une image personnalisÃ©e, et aborder les bonnes pratiques de crÃ©ation dâ€™images.

### 4.1 Syntaxe et instructions dâ€™un Dockerfile

Un **Dockerfile** est un simple fichier texte (gÃ©nÃ©ralement nommÃ© "Dockerfile" sans extension) qui dÃ©finit pas Ã  pas comment construire une image. Chaque ligne du Dockerfile est une **instruction** qui correspond Ã  une action (par exemple installer un package, copier des fichiers, dÃ©finir une variable dâ€™environnement, etc.). Docker va lire ces instructions et les exÃ©cuter successivement pour produire lâ€™image finale.

Voici les instructions les plus courantes dans un Dockerfile et leur rÃ´le :

| **Instruction**  | **Description**                                                    | **Exemple**                        |
|------------------|--------------------------------------------------------------------|------------------------------------|
| `FROM`           | SpÃ©cifie lâ€™image de base Ã  partir de laquelle on construit. Câ€™est la premiÃ¨re ligne obligatoire de tout Dockerfile. | `FROM python:3.11-slim` (base Debian avec Python 3.11) |
| `RUN`            | ExÃ©cute une commande durant la construction de lâ€™image. Chaque `RUN` crÃ©e une nouvelle couche dans lâ€™image. UtilisÃ© typiquement pour installer des paquets ou configurer le systÃ¨me. | `RUN apt-get update && apt-get install -y curl` |
| `COPY`           | Copie des fichiers ou dossiers du *contexte de construction* (votre machine hÃ´te) vers le systÃ¨me de fichiers de lâ€™image. | `COPY src/ /app/src/` (copie le dossier src local vers /app/src dans lâ€™image) |
| `ADD`            | Similaire Ã  COPY (copie fichiers locaux ou URL). Moins utilisÃ©, sauf si besoin dâ€™extraire une archive (ADD sait dÃ©zipper les *.tar*). | `ADD app.tar.gz /app/` |
| `WORKDIR`        | DÃ©finit le rÃ©pertoire de travail courant pour les instructions suivantes et pour le conteneur final. (Equivalent Ã  un `cd` persistent). | `WORKDIR /app` |
| `ENV`            | DÃ©finit une variable dâ€™environnement dans lâ€™image. Utile pour configurer lâ€™application ou indiquer des chemins. | `ENV NODE_ENV=production` |
| `EXPOSE`         | Documente le port sur lequel lâ€™application Ã©coute. **Note :** Câ€™est indicatif, cela **nâ€™ouvre pas** le port sur lâ€™hÃ´te. (Pour rendre le service accessible, on utilise `-p` Ã  lâ€™exÃ©cution du conteneur). | `EXPOSE 8080` |
| `CMD`            | SpÃ©cifie la commande par dÃ©faut Ã  exÃ©cuter lorsque le conteneur est lancÃ©. Câ€™est le *point dâ€™entrÃ©e* de votre application. Si on passe des arguments Ã  `docker run`, ils viendront surcharger le CMD. | `CMD ["python", "app.py"]` |
| `ENTRYPOINT`     | DÃ©finis le processus principal du conteneur, de maniÃ¨re impÃ©rative. CombinÃ© avec CMD (qui peut fournir des arguments par dÃ©faut). En gÃ©nÃ©ral on utilise soit ENTRYPOINT soit CMD pour lancer lâ€™appli. | `ENTRYPOINT ["npm", "start"]` |

En plus de ces instructions, il en existe dâ€™autres (comme `LABEL` pour ajouter des mÃ©tadonnÃ©es, `ARG` pour les variables de build, `USER` pour changer lâ€™utilisateur dâ€™exÃ©cution, etc.), mais les listÃ©es ci-dessus sont suffisantes pour dÃ©buter.

Lorsquâ€™on exÃ©cute `docker build` pour construire lâ€™image, Docker lit le Dockerfile et traite chaque instruction dans lâ€™ordre. Chaque instruction (FROM, RUN, COPY, etc.) crÃ©e une **couche** de lâ€™image. Docker va mettre en cache ces couches pour accÃ©lÃ©rer les reconstructions futures : si le Dockerfile nâ€™a pas changÃ© Ã  un certain stade, Docker peut rÃ©utiliser la couche existante au lieu de la reconstruire. **Important :** lâ€™ordre des instructions impacte le cache. Il est courant dâ€™ordonner le Dockerfile du gÃ©nÃ©ral au particulier afin de maximiser la rÃ©utilisation du cache (voir bonnes pratiques plus bas).

Pour illustrer, Ã©crivons un Dockerfile simple pour une application Python :

```dockerfile
# Utiliser l'image de base Python officielle (version 3.11 slim)
FROM python:3.11-slim

# DÃ©finir le dossier de travail Ã  /app
WORKDIR /app

# Copier le fichier de dÃ©pendances et installer les dÃ©pendances
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copier le reste du code de l'application
COPY . .

# Exposer le port de l'application (exemple: une app web sur le port 5000)
EXPOSE 5000

# Lancer l'application
CMD ["python", "app.py"]
```

Analysons ce Dockerfile :
- On part dâ€™une image de base lÃ©gÃ¨re (`python:3.11-slim`) contenant Python 3.11 sur un OS minimal.
- On se place dans le rÃ©pertoire `/app` dans lâ€™image.
- On copie le fichier `requirements.txt` (qui liste les paquets Python nÃ©cessaires) puis on exÃ©cute `pip install` pour installer ces dÃ©pendances. En sÃ©parant COPY et RUN de cette maniÃ¨re, on optimise le cache : si seul le code de lâ€™appli change mais pas les dÃ©pendances, Docker pourra re-utiliser la couche dâ€™installation des requirements.
- On copie ensuite tout le reste du projet dans lâ€™image (`COPY . .`).
- On documente que lâ€™application Ã©coute sur le port 5000.
- Enfin, on dÃ©finit la commande de lancement : ici, exÃ©cuter `python app.py`. Ainsi, quand on fera `docker run` sur lâ€™image rÃ©sultante, le conteneur dÃ©marrera notre application Python automatiquement.

### 4.2 Construction de lâ€™image Docker

Avec notre Dockerfile en place, construisons lâ€™image. Assurez-vous dâ€™Ãªtre dans le rÃ©pertoire oÃ¹ se trouve le Dockerfile (et les fichiers de lâ€™application). Puis lancez la commande de build :

```bash
docker build -t monapp:1.0 .
```

Ici, `-t monapp:1.0` assigne un *tag* Ã  lâ€™image (nom de lâ€™image = "monapp", tag = "1.0"). Le `.` final indique que le *contexte de build* est le rÃ©pertoire courant (Docker va envoyer ce dossier au dÃ©mon Docker pour quâ€™il accÃ¨de aux fichiers Ã  copier). Docker va alors exÃ©cuter chaque instruction :
- TÃ©lÃ©charger lâ€™image de base python:3.11-slim (si pas dÃ©jÃ  en cache local).
- ExÃ©cuter les commandes RUN (mise Ã  jour pip, installation des dÃ©pendances).
- etc.

Vous verrez dans la console la progression, Ã©tape par Ã©tape. Si tout se passe bien, Docker conclura par un message du type *Successfully built <image-id>* et *Successfully tagged monapp:1.0*.

Notre image `monapp:1.0` est maintenant construite. On peut la lister avec `docker images` (elle apparaÃ®tra avec le nom et tag spÃ©cifiÃ©s). Testons-la en lanÃ§ant un conteneur :

```bash
docker run -d -p 5000:5000 monapp:1.0
```

Cette commande exÃ©cute notre application Python en dÃ©tachÃ©. Supposons que câ€™est une petite API web Flask Ã©coutant sur le port 5000 ; grÃ¢ce au mapping `-p 5000:5000`, elle est accessible via `http://localhost:5000`. Si besoin, on consulte les logs (`docker logs <container_id>`) pour vÃ©rifier que tout se passe bien. Notre image personnalisÃ©e fonctionne !

**Gestion des images** : Vous pouvez retagger ou pousser cette image vers un registre. Par exemple, pour envoyer `monapp:1.0` sur Docker Hub, il faudrait la taguer en `docker tag monapp:1.0 monDockerHubUtilisateur/monapp:1.0` puis exÃ©cuter `docker push monDockerHubUtilisateur/monapp:1.0` (aprÃ¨s sâ€™Ãªtre authentifiÃ© via `docker login`). Nous reviendrons sur lâ€™automatisation de ces Ã©tapes dans la section CI/CD.

Un aspect fondamental Ã  comprendre est la notion de *couches*. Chaque commande du Dockerfile a crÃ©Ã© une couche dans lâ€™image. Docker rÃ©utilise ces couches lors de constructions ultÃ©rieures pour Ã©viter de tout refaire Ã  zÃ©r ([Docker, c'est quoi ?](https://www.redhat.com/fr/topics/containers/what-is-docker#:~:text=,version%20des%20images))ã€‘. Par exemple, si vous modifiez juste le code applicatif mais pas le fichier requirements.txt, Docker reprendra le cache jusquâ€™Ã  lâ€™Ã©tape dâ€™installation des dÃ©pendances, puis ne reconstruira que la copie du code et la couche finale. Cela accÃ©lÃ¨re Ã©normÃ©ment les itÃ©rations.

### 4.3 Bonnes pratiques pour les Dockerfile

Lors de la crÃ©ation dâ€™images Docker, quelques bonnes pratiques permettent dâ€™obtenir des images plus petites, plus efficaces et plus sÃ»res :

- **Minimiser la taille des images** : Utilisez des images de base lÃ©gÃ¨res (*slim*, *alpine* etc. lorsquâ€™elles existent). Ã‰vitez dâ€™installer des packages inutiles. Nettoyez le cache des gestionnaires de paquets (par ex. ajouter `rm -rf /var/lib/apt/lists/*` aprÃ¨s un `apt-get install` dans le mÃªme `RUN`) pour rÃ©duire la taille des couches. Des images plus petites se dÃ©ploient plus vite et ont une surface dâ€™attaque rÃ©duite.
- **Tirer parti du cache** : Organisez les instructions du Dockerfile de faÃ§on logique pour maximiser la rÃ©utilisation du cache. Par exemple, placez les instructions qui changent le moins (installation de dÃ©pendances systÃ¨me, etc.) au dÃ©but, et les parties qui changent frÃ©quemment (copie du code source de lâ€™application) vers la fin. Ainsi, vous ne refaites pas les Ã©tapes lourdes Ã  chaque modification mineure du code.
- **Utiliser un fichier .dockerignore** : CrÃ©ez un fichier `.dockerignore` pour exclure du contexte de build les fichiers qui ne sont pas nÃ©cessaires Ã  lâ€™image (ex: fichiers temporaires, `.git`, documentation, etc.). Cela accÃ©lÃ¨re la construction et Ã©vite dâ€™embarquer des fichiers inutiles dans lâ€™image.
- **Un seul processus par conteneur** : Par convention, chaque conteneur Docker ne doit exÃ©cuter quâ€™un seul processus principal. Par exemple, ne lancez pas Ã  la fois une base de donnÃ©es et un serveur web dans le mÃªme conteneur â€“ prÃ©fÃ©rez deux conteneurs sÃ©parÃ©s. Docker nâ€™est pas une machine virtuelle gÃ©nÃ©rale, mais une sandbox pour une application unique (on peut tout de mÃªme avoir des processus auxiliaires si besoin, mais lâ€™idÃ©e est de dÃ©couper en micro-services).
- **Ã‰viter dâ€™exÃ©cuter en root** : Par dÃ©faut, un conteneur tourne en tant quâ€™utilisateur root (superutilisateur) Ã  lâ€™intÃ©rieur. Cela peut poser des problÃ¨mes de sÃ©curitÃ© si quelquâ€™un parvient Ã  sâ€™Ã©chapper du conteneur. Quand câ€™est possible, crÃ©ez un utilisateur dÃ©diÃ© dans lâ€™image (`RUN adduser ...` puis `USER <nom>` dans le Dockerfile) pour exÃ©cuter lâ€™application avec moins de privilÃ¨ges. De nombreuses images officielles (ex: Node, Nginx) proposent dÃ©jÃ  un utilisateur non-root par dÃ©faut pour lâ€™exÃ©cution.
- **Tenir compte du rÃ©seau et du stockage** : Documentez avec `EXPOSE` les ports utilisÃ©s par votre application dans le Dockerfile (cela aide les autres Ã  comprendre comment lâ€™utiliser, mÃªme si ce nâ€™est pas obligatoire). Idem, si votre application doit stocker des donnÃ©es persistantes, envisagez dâ€™utiliser lâ€™instruction `VOLUME` pour indiquer quel chemin devra Ãªtre montÃ© en volume lors de lâ€™exÃ©cution du conteneur. (Nous verrons les volumes au chapitre suivant.)

En suivant ces conseils, vos images seront plus faciles Ã  maintenir et Ã  dÃ©ployer. Vous trouverez sur le web (docs Docker, blogs) des *Dockerfile best practices* plus dÃ©taillÃ©es, mais ces bases vous permettront dâ€™Ã©viter les Ã©cueils classiques (images trop lourdes, builds lents, failles de sÃ©curitÃ© basiques).

## 5. Gestion des volumes et des rÃ©seaux

Lorsque vous lancez des conteneurs, deux aspects importants entrent en jeu : la **persistance des donnÃ©es** (les volumes) et la **communication rÃ©seau** entre conteneurs ou avec lâ€™extÃ©rieur. Par dÃ©faut, un conteneur Docker est Ã©phÃ©mÃ¨re et relativement isolÃ© sur le plan rÃ©seau. Voyons comment conserver des donnÃ©es au-delÃ  du cycle de vie dâ€™un conteneur grÃ¢ce aux volumes, puis comment fonctionnent les rÃ©seaux Docker.

### 5.1 Les volumes : persistance des donnÃ©es

Par design, les donnÃ©es Ã©crites Ã  lâ€™intÃ©rieur dâ€™un conteneur (dans son systÃ¨me de fichiers isolÃ©) disparaissent lorsque le conteneur est supprimÃ©. Docker propose les **volumes** pour sauvegarder des donnÃ©es de maniÃ¨re persistante, indÃ©pendamment du cycle de vie des conteneurs. Un volume est une zone de stockage gÃ©rÃ©e par Docker, gÃ©nÃ©ralement stockÃ©e sur lâ€™hÃ´te, que lâ€™on peut monter dans un ou plusieurs conteneurs.

**Pourquoi des volumes ?** Prenons lâ€™exemple dâ€™une base de donnÃ©es dans un conteneur : sans volume, toutes les donnÃ©es seraient perdues Ã  lâ€™arrÃªt/suppression du conteneur (ou lors dâ€™une mise Ã  jour de lâ€™image). En utilisant un volume, on attache un dossier persistant Ã  lâ€™emplacement oÃ¹ la base stocke ses fichiers, ce qui permet de conserver les donnÃ©es mÃªme si le conteneur est recrÃ©Ã© ou mis Ã  jour.

Il existe principalement deux types de volumes/montages avec Docker :
- **Volumes nommÃ©s (managed volumes)** â€“ Stockage gÃ©rÃ© par Docker, dans un emplacement interne (par dÃ©faut sous `/var/lib/docker/volumes/`). On les crÃ©e via Docker (`docker volume create`) ou automatiquement au `docker run`. Ils sont identifiÃ©s par un nom attribuÃ©. Exemple : `docker run -d -v monvolume:/var/lib/mysql mysql:8` va crÃ©er (si inexistant) un volume nommÃ© *monvolume* et le monter dans le conteneur Ã  lâ€™emplacement `/var/lib/mysql`. Si vous supprimez le conteneur, le volume *monvolume* existe toujours et pourra Ãªtre remontÃ© sur un autre conteneur pour rÃ©cupÃ©rer les donnÃ©es.
- **Bind mounts (montages de rÃ©pertoire)** â€“ Montage direct dâ€™un rÃ©pertoire du systÃ¨me hÃ´te dans le conteneur. On fournit un chemin absolu de lâ€™hÃ´te. Exemple : `docker run -d -v /home/user/backup:/backup alpine tar czf /backup/etc.tar.gz /etc`. Ici, on monte le dossier `/home/user/backup` du host dans le conteneur comme `/backup`. Le conteneur (une Alpine Linux) crÃ©e une archive de /etc et la place dans /backup, qui en rÃ©alitÃ© est stockÃ© sur lâ€™hÃ´te. Les bind mounts permettent donc un contrÃ´le exact de lâ€™emplacement des donnÃ©es sur lâ€™hÃ´te. Ils sont souvent utilisÃ©s en dÃ©veloppement pour monter le code source local dans le conteneur (ainsi lâ€™application voit les modifications de code en temps rÃ©el), ou pour accÃ©der Ã  des fichiers spÃ©cifiques du host.

En rÃ©sumÃ©, utilisez de prÃ©fÃ©rence des **volumes nommÃ©s** pour la persistance applicative (base de donnÃ©es, fichiers import/uploads, etc.), car Docker les gÃ¨re pour vous (pas besoin de connaÃ®tre le chemin exact sur lâ€™hÃ´te, ce qui amÃ©liore la portabilitÃ©). Les **bind mounts** sont utiles pour des cas oÃ¹ vous avez besoin de contrÃ´ler prÃ©cisÃ©ment le chemin hÃ´te ou de partager des fichiers spÃ©cifiques entre host et conteneur.

Voyons quelques commandes liÃ©es aux volumes :
- `docker volume create <nom>` crÃ©e un volume persistant vide.
- `docker volume ls` liste les volumes Docker existants.
- `docker volume inspect <nom>` donne des infos (notamment le chemin sur lâ€™hÃ´te oÃ¹ sont stockÃ©es les donnÃ©es du volume).
- `docker volume rm <nom>` supprime un volume (attention, cela efface les donnÃ©es â€“ Docker nâ€™autorise pas la suppression dâ€™un volume sâ€™il est utilisÃ© par un conteneur actif).

**Exemple dâ€™utilisation de volume :** Supposons que nous dÃ©ployons MySQL via Docker. Pour que la base sauvegarde ses donnÃ©es hors du conteneur, on peut lancer:
```bash
docker volume create db_data        # crÃ©er un volume pour la base
docker run -d -v db_data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=secret mysql:8
``` 
Ici on a spÃ©cifiquement montÃ© le volume `db_data` sur `/var/lib/mysql` (dossier oÃ¹ MySQL stocke ses bases). On a Ã©galement passÃ© une variable dâ€™env pour le mot de passe root (juste pour que MySQL se lance). Ainsi, mÃªme si ce conteneur MySQL sâ€™arrÃªte ou est supprimÃ©, les donnÃ©es resteront dans `db_data`. On pourrait lancer une nouvelle version de MySQL et remonter `db_data` pour rÃ©cupÃ©rer immÃ©diatement lâ€™Ã©tat prÃ©cÃ©dent de la base.

**Partage de volumes entre conteneurs :** Plusieurs conteneurs peuvent accÃ©der au mÃªme volume (typique par ex. si vous avez un conteneur dâ€™application et un conteneur de backup qui doit lire les mÃªmes fichiers). Il faut toutefois faire attention aux accÃ¨s concurrents. Docker ne verrouille pas les volumes â€“ câ€™est Ã  vous de sâ€™assurer que câ€™est safe (par ex. un conteneur en lecture seule).

**Ã‰criture sur volume vs couche conteneur :** Notez que si un fichier est modifiÃ© Ã  lâ€™intÃ©rieur dâ€™un conteneur :
- Sâ€™il fait partie dâ€™un volume montÃ©, la modification impacte directement le volume (persistant).
- Sâ€™il fait partie de lâ€™image (pas dans un volume), la modification est faite dans la couche *conteneur* (copy-on-write). Ces changements-lÃ  sont perdus quand le conteneur est supprimÃ©. On Ã©vite gÃ©nÃ©ralement de sâ€™appuyer lÃ -dessus pour du stockage applicatif.

### 5.2 Les rÃ©seaux Docker

Par dÃ©faut, Docker isole aussi le rÃ©seau des conteneurs : chaque conteneur a sa propre pile rÃ©seau et ne voit pas directement les autres. Comprendre le fonctionnement rÃ©seau de Docker est crucial pour faire communiquer des conteneurs entre eux ou exposer des services Ã  lâ€™extÃ©rieur.

**RÃ©seau *bridge* par dÃ©faut :** Lorsque vous installez Docker, un rÃ©seau *bridge* nommÃ© `bridge` est crÃ©Ã© automatiquement. Si vous lancez un conteneur sans prÃ©ciser de rÃ©seau, il est attachÃ© Ã  ce rÃ©seau par dÃ©faut. Le rÃ©seau bridge agit comme un sous-rÃ©seau virtuel interne Ã  la machine Docker :
- Les conteneurs sur ce rÃ©seau peuvent communiquer entre eux **par IP** (Docker leur attribue une IP locale, ex: 172.17.0.X). Cependant, ils ne connaissent pas automatiquement les noms des autres conteneurs. Sur le rÃ©seau par dÃ©faut, il nâ€™y a pas de DNS conteneur -> conteneur.
- Les conteneurs peuvent accÃ©der Ã  Internet (par NAT) via le rÃ©seau du host. En revanche, de lâ€™extÃ©rieur on ne peut pas atteindre un port dâ€™un conteneur sans un *port mapping* explicite (`-p host_port:container_port` lors du run).
- Le host (votre machine) peut contacter un conteneur sur le bridge via son IP docker interne, mais câ€™est peu pratique (on privilÃ©gie le port mapping ou lâ€™utilisation de `docker exec` pour communiquer).

**RÃ©seaux *bridge* personnalisÃ©s :** Docker permet de crÃ©er vos propres rÃ©seaux virtuels isolÃ©s. Par exemple, si vous faites :
```bash
docker network create monreseau
```
vous obtenez un nouveau rÃ©seau de type bridge nommÃ© *monreseau*. Les conteneurs que vous lancerez avec `--network monreseau` seront connectÃ©s ensemble sur ce rÃ©seau. Lâ€™avantage principal dâ€™un rÃ©seau personnalisÃ© est que Docker configure un **serveur DNS interne** pour ce rÃ©seau : ainsi, les conteneurs peuvent se rÃ©soudre par nom dâ€™hÃ´te. ConcrÃ¨tement, si vous lancez deux conteneurs sur *monreseau*, lâ€™un nommÃ© `web` et lâ€™autre `db`, alors dans le conteneur `web`, le nom dâ€™hÃ´te `db` rÃ©soudra automatiquement vers lâ€™IP du conteneur `db`. Pas besoin de connaÃ®tre les adresses IP. Ceci simplifie grandement la communication dans des architectures multi-conteneurs (et câ€™est ce que fait Docker Compose automatiquement, nous y viendrons).

Pour attacher un conteneur Ã  un rÃ©seau existant, utilisez `--network` Ã  la crÃ©ation. Exemple :
```bash
docker run -d --name web --network monreseau nginx
docker run -d --name db --network monreseau mysql:8
```
Ici, `web` et `db` sont sur le mÃªme rÃ©seau isolÃ© *monreseau*. Le conteneur `web` peut contacter `db` en utilisant lâ€™adresse `db:3306` (3306 Ã©tant le port MySQL standard). Ce genre de rÃ©seau est isolÃ© du rÃ©seau par dÃ©faut et des autres rÃ©seaux Docker, ce qui offre une bonne Ã©tanchÃ©itÃ© entre diffÃ©rentes applications sur une mÃªme machine.

**Autres types de rÃ©seau :** Docker propose deux autres drivers de rÃ©seau principaux :
- **host** â€“ En mode host, un conteneur partage directement la pile rÃ©seau de lâ€™hÃ´te, il nâ€™y a pas dâ€™isolation rÃ©seau. Le conteneur nâ€™a pas sa propre IP : il utilise celle du host. Par exemple, si on lance `docker run --network host -p 8080:80 nginx`, le `-p` nâ€™a plus lieu dâ€™Ãªtre car le conteneur *est* dÃ©jÃ  sur le host : Nginx Ã©coutera directement sur le port 80 du host. Le mode host peut amÃ©liorer la performance rÃ©seau (pas de NAT) et est utile pour des conteneurs qui doivent accÃ©der Ã  des services sur localhost (host) ou diffuser en rÃ©seau local. Par contre, câ€™est moins isolÃ© (ports conteneur = ports host, donc risques de conflits).
- **none** â€“ Câ€™est lâ€™inverse : pas de rÃ©seau du tout. Le conteneur nâ€™a aucune interface rÃ©seau (Ã  part *lo* interne). Il ne peut pas communiquer, ni Ãªtre contactÃ©. Ce mode ultra-isolÃ© sert pour des cas trÃ¨s spÃ©cifiques (par exemple des tests de sÃ©curitÃ©, ou forcer quâ€™une appli ne fasse aucune communication).

**RÃ©sumÃ© des modes rÃ©seau :**

- **Bridge par dÃ©faut** : isolation modÃ©rÃ©e, communication conteneur->conteneur par IP, nÃ©cessite des mapping de ports pour lâ€™accÃ¨s externe. Convenable pour dÃ©buter ou conteneurs isolÃ©s.
- **Bridge personnalisÃ©** : isolation entre applications, mais conteneurs sur un mÃªme rÃ©seau peuvent se joindre par nom. RecommandÃ© pour les applications multi-conteneurs (et câ€™est ce quâ€™utilise Compose).
- **Host** : conteneur fusionnÃ© avec le rÃ©seau de lâ€™hÃ´te. Utile pour besoins particuliers (performance, accÃ¨s local), Ã  utiliser prudemment.
- **None** : pas de rÃ©seau, cas extrÃªmes.

**Exposer un port :** Comme vu prÃ©cÃ©demment, pour rendre un service conteneur accessible depuis lâ€™hÃ´te (ou lâ€™extÃ©rieur), il faut publier son port via `-p`. Par exemple, `-p 8080:80` expose sur le port 8080 de toutes les interfaces de lâ€™hÃ´te. Vous pouvez restreindre Ã  une IP spÃ©cifique de lâ€™hÃ´te en prÃ©fixant (ex: `-p 127.0.0.1:8080:80` Ã©coutera uniquement en localhost). Sans mapping, un conteneur web dans Docker ne sera pas visible depuis lâ€™extÃ©rieur.

**Connexion de conteneurs entre plusieurs hÃ´tes :** Le Docker de base ne connecte pas des conteneurs sur des machines diffÃ©rentes. Pour cela, Docker propose un driver de rÃ©seau *overlay* utilisable avec Docker Swarm (le mode cluster natif de Docker) â€“ cela dÃ©passe notre scope ici. En gÃ©nÃ©ral, pour un rÃ©seau multi-hÃ´tes, on utilise une surcouche dâ€™orchestration comme Kubernetes ou Docker Swarm qui se charge de crÃ©er un rÃ©seau distribuÃ©.

En pratique, si vous utilisez **Docker Compose** (chapitre suivant), celui-ci crÃ©e automatiquement un rÃ©seau dÃ©diÃ© pour vos conteneurs du compose, ce qui leur permet de se dÃ©couvrir par nom de service. Cela facilite la vie : plus besoin de crÃ©er manuellement le rÃ©seau ou de lâ€™indiquer dans chaque commande `docker run`. Nous allons voir cela immÃ©diatement avec Compose.

## 6. Docker Compose

GÃ©rer manuellement plusieurs conteneurs avec les commandes Docker de base peut devenir fastidieux, surtout lorsquâ€™il faut se souvenir de lancer X conteneurs avec les bons paramÃ¨tres dans le bon ordre. **Docker Compose** est un outil qui simplifie le dÃ©ploiement de multi-conteneurs dÃ©finis dÃ©clarativement dans un fichier YAML. Il permet, avec une seule commande, de lancer (ou arrÃªter) tout un ensemble de conteneurs qui forment une application.

### 6.1 PrÃ©sentation de Docker Compose

Docker Compose utilise un fichier typiquement nommÃ© `docker-compose.yml` oÃ¹ vous dÃ©crivez les services (conteneurs) composant votre application, ainsi que leurs configurations :
images Ã  utiliser (ou Dockerfile Ã  construire), ports exposÃ©s, volumes montÃ©s, variables dâ€™environnement, dÃ©pendances entre services, rÃ©seaux, etc. Ensuite, la commande `docker-compose up` (ou la nouvelle syntaxe `docker compose up`) va automatiquement crÃ©er tous les conteneurs dÃ©finis et les configurer selon le YAML.

Compose est trÃ¨s pratique en dÃ©veloppement et test, car il permet de reproduire une architecture (ex: une app web + une base de donnÃ©es + un cache) sur une seule machine de faÃ§on cohÃ©rente. En production, on utilisera plutÃ´t Kubernetes ou Swarm, mais Compose reste utile pour orchestrer des conteneurs sur un seul hÃ´te ou pour les pipelines CI.

Quelques bÃ©nÃ©fices de Compose :
- **Lancement unifiÃ©** : un simple `docker-compose up -d` peut lancer une base de donnÃ©es, un backend API et un frontend, reliÃ©s et configurÃ©s.
- **RÃ©seau automatique** : comme mentionnÃ©, Compose crÃ©e un rÃ©seau bridge spÃ©cifique sur lequel il connecte tous les services, avec rÃ©solution DNS par nom de service.
- **Variables dâ€™environnement** : on peut utiliser un fichier `.env` ou passer des env au conteneur facilement via le YAML.
- **Orchestration simple** : Compose assure de lancer dâ€™abord les conteneurs dont dâ€™autres dÃ©pendent (grÃ¢ce Ã  lâ€™instruction `depends_on`). Il permet aussi de reconstruire des images (`docker-compose build`) et de les lancer, de surveiller les logs de lâ€™ensemble (`docker-compose logs`), etc.

### 6.2 Syntaxe de docker-compose.yml

Le format du fichier Compose est en YAML. Voici les Ã©lÃ©ments principaux :
- `version` : la version du format Compose (par ex. "3.8"). Les versions 3.x sont les plus courantes avec Docker >= 20.
- `services` : la liste des services (chaque service correspondra Ã  un conteneur, ou Ã  un ensemble de conteneurs identiques si on scale).
- Pour chaque service :
  - soit un champ `image: nom_image:tag` pour indiquer quelle image utiliser,
  - soit un bloc `build:` si on veut construire lâ€™image Ã  partir dâ€™un Dockerfile (on peut mettre `build: .` pour construire depuis le Dockerfile du dossier courant).
  - des `ports:` Ã  publier (format `"hÃ´te:conteneur"` comme en ligne de commande),
  - des `environment:` pour les variables dâ€™env (liste ou dict YAML),
  - des `volumes:` pour monter des volumes ou bind mounts,
  - un `depends_on:` listant les autres services du compose qui doivent dÃ©marrer avant celui-ci.
  - Ã©ventuellement `networks:` si on a plusieurs rÃ©seaux personnalisÃ©s, ou `restart:` pour dÃ©finir une politique de redÃ©marrage automatique (ex: always).

- On peut Ã©galement dÃ©finir des `volumes:` (nommÃ©s) au niveau top-level du fichier, que les services utiliseront, ainsi que des `networks:` si besoin de rÃ©seaux spÃ©cifiques. Par dÃ©faut, si on ne dÃ©finit rien, Compose crÃ©e un rÃ©seau implicite du nom du projet, et les volumes nommÃ©s dÃ©clarÃ©s dans services seront aussi crÃ©Ã©s automatiquement.

Pour illustrer, Ã©crivons un exemple concret de `docker-compose.yml`. Imaginons que lâ€™on souhaite dÃ©ployer une application WordPress avec une base de donnÃ©es MySQL. Nous aurons deux services : *wordpress* (le serveur web+php) et *db* (MySQL). Nous voulons persister les donnÃ©es de la base dans un volume. Voici Ã  quoi pourrait ressembler le fichier Compose :

```yaml
services:
  db:
    image: mysql:5.7
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=exemple
      - MYSQL_DATABASE=wordpress
    volumes:
      - db_data:/var/lib/mysql

  wordpress:
    image: wordpress:latest
    restart: always
    ports:
      - "8080:80"
    environment:
      - WORDPRESS_DB_HOST=db:3306
      - WORDPRESS_DB_PASSWORD=exemple
      - WORDPRESS_DB_NAME=wordpress
    depends_on:
      - db

volumes:
  db_data:
```

Analysons les points clÃ©s de ce fichier :

- Nous utilisons deux images officielles : **mysql:5.7** pour la base, **wordpress:latest** pour lâ€™application PHP.
- Chaque service a une politique `restart: always` : cela indique Ã  Docker de toujours redÃ©marrer le conteneur en cas dâ€™arrÃªt (ou au dÃ©marrage du Docker daemon). Câ€™est une bonne pratique en production pour les conteneurs critiques.
- Le service **db** reÃ§oit des variables dâ€™environnement :
  - `MYSQL_ROOT_PASSWORD` pour dÃ©finir le mot de passe root de MySQL,
  - `MYSQL_DATABASE` pour crÃ©er une base nommÃ©e *wordpress* dâ€™entrÃ©e de jeu.
- On monte un volume nommÃ© `db_data` sur `/var/lib/mysql` afin de conserver les donnÃ©es de la base MySQL.
- Le service **wordpress** publie le port 80 du conteneur sur le port 8080 de lâ€™hÃ´te (on pourra accÃ©der au site sur http://localhost:8080).
- WordPress a besoin de se connecter Ã  la base de donnÃ©es. On lui fournit:
  - `WORDPRESS_DB_HOST=db:3306` : lâ€™adresse du serveur MySQL. Ici on utilise le nom de service `db` qui sera rÃ©solu automatiquement grÃ¢ce au rÃ©seau Compose, et le port standard 3306.
  - `WORDPRESS_DB_PASSWORD=exemple` et `WORDPRESS_DB_NAME=wordpress` pour quâ€™il puisse se connecter avec lâ€™utilisateur root et la base configurÃ©e.
- `depends_on: db` indique que le conteneur *wordpress* ne sera dÃ©marrÃ© quâ€™aprÃ¨s le lancement du conteneur *db*. (Ã‡a ne signifie pas que MySQL sera prÃªt instantanÃ©ment, mais au moins lâ€™ordre est respectÃ©.)
- En bas, on dÃ©clare le volume `db_data` afin que Compose le crÃ©e (sâ€™il nâ€™existe pas dÃ©jÃ ). Ainsi, la premiÃ¨re exÃ©cution va crÃ©er un volume persistant, et les suivantes rÃ©utiliseront le mÃªme.

**DÃ©marrer lâ€™application avec Compose :** placez ce YAML dans un fichier `docker-compose.yml`. Dans le mÃªme dossier, exÃ©cutez la commande :
```bash
docker-compose up -d
``` 
*(Ou `docker compose up -d` selon votre version, les deux syntaxes fonctionnent.)* 

Compose va alors :
- CrÃ©er le rÃ©seau `monDossier_default` (si non existant) et le volume `db_data`.
- Lancer le conteneur **db** (MySQL), puis le conteneur **wordpress**.
- Les deux conteneurs seront connectÃ©s au rÃ©seau commun, et pourront communiquer (WordPress -> MySQL).
- Vous pouvez surveiller le dÃ©marrage avec `docker-compose logs -f` pour voir, par exemple, MySQL initialiser sa base puis WordPress se connecter.

AprÃ¨s quelques secondes, en visitant `http://localhost:8080`, vous devriez voir lâ€™Ã©cran dâ€™installation de WordPress ğŸ‰. Tout cela a Ã©tÃ© rÃ©alisÃ© avec un unique fichier de configuration et une commande â€“ plutÃ´t que de lancer manuellement 2 conteneurs avec une panoplie de paramÃ¨tres.

**Utilisation au quotidien :** 
- `docker-compose ps` liste les conteneurs gÃ©rÃ©s par le compose en cours (dans le dossier courant).
- `docker-compose down` arrÃªte et supprime les conteneurs (ainsi que les rÃ©seaux associÃ©s). Les volumes persistants, eux, ne sont pas supprimÃ©s par dÃ©faut (ce qui est bien pour ne pas perdre les donnÃ©es).
- Si vous modifiez le fichier compose (par ex, changer une variable dâ€™env ou la version dâ€™une image), il suffit de re-exÃ©cuter `docker-compose up -d` pour appliquer les changements (Compose fera les mises Ã  jour nÃ©cessaires, recrÃ©era les conteneurs concernÃ©s).
- `docker-compose build` permet de construire les images si vous avez des services avec un contexte de build (Dockerfile). Sinon, Compose va toujours chercher les images sur Docker Hub automatiquement.

Docker Compose est un outil prÃ©cieux pour tester des configurations complexes sur votre machine ou pour dÃ©ployer des stacks simples sur un serveur unique. Il est Ã©galement trÃ¨s utilisÃ© dans les scÃ©narios de dÃ©veloppement, pour lancer rapidement lâ€™environnement complet (ex: lancer Ã  la fois votre API, la base de donnÃ©es et Redis en une commande). Nous verrons dans lâ€™Ã©tude de cas finale comment lâ€™utiliser dans un workflow de projet.

## 7. DÃ©ploiement en production sur un VPS Linux

Lorsque vous passez en **production** (par exemple dÃ©ployer vos conteneurs sur un serveur cloud ou un VPS), de nouvelles considÃ©rations entrent en jeu : il faut sÃ©curiser les dÃ©ploiements, assurer la haute disponibilitÃ©, gÃ©rer les mises Ã  jour sans coupure, collecter les logs et monitorer les conteneurs en service. Dans cette section, nous allons prÃ©senter des bonnes pratiques pour dÃ©ployer Docker en production sur un serveur Linux, en couvrant la sÃ©curisation, lâ€™opÃ©rationnel et la supervision.

### 7.1 SÃ©curisation des conteneurs

Bien que Docker offre une isolation, en production il est crucial de renforcer la sÃ©curitÃ© :

- **Utiliser des images fiables et mises Ã  jour** : Ne tÃ©lÃ©chargez des images quâ€™Ã  partir de sources de confiance (Docker Official Images, Ã©diteurs reconnus, ou vos propres images construites). Mettez Ã  jour rÃ©guliÃ¨rement vos images pour intÃ©grer les derniers patchs de sÃ©curitÃ©. Par exemple, si une faille est dÃ©couverte dans PHP, assurez-vous de rÃ©cupÃ©rer une image mise Ã  jour dÃ¨s que possible.
- **Principe de moindre privilÃ¨ge** : Faites tourner vos conteneurs avec le moins de privilÃ¨ges possible. Comme mentionnÃ©, Ã©vitez de lancer vos processus applicatifs en root Ã  lâ€™intÃ©rieur du conteneur. De plus, Docker permet dâ€™ajouter des options de sÃ©curitÃ© lors du `docker run` â€“ par ex : `--read-only` (monter le systÃ¨me de fichiers conteneur en lecture seule), `--cap-drop` (retirer des *capabilities* Linux du conteneur pour limiter ce quâ€™il peut faire), `--security-opt no-new-privileges` (empÃªcher lâ€™escalade de privilÃ¨ges). Ces options renforcent lâ€™isolation.
- **Limiter lâ€™exposition rÃ©seau** : Nâ€™exposez que les ports nÃ©cessaires. Si un conteneur nâ€™a pas vocation Ã  Ãªtre accessible directement depuis Internet, ne faites pas de `-p` vers lâ€™hÃ´te. Laissez-le dans le rÃ©seau interne Docker, et faites passer les communications via un proxy ou un service dÃ©diÃ©. Par exemple, en production on utilise souvent un **reverse proxy** (Nginx, Traefik) unique exposÃ© sur le port 80/443, qui redirige les requÃªtes vers les conteneurs webs en interne â€“ cela Ã©vite dâ€™exposer chaque conteneur web individuellement.
- **Pare-feu au niveau de lâ€™hÃ´te** : Configurez un firewall (iptables, UFW, etc.) sur votre serveur Docker pour filtrer les ports. Par dÃ©faut Docker ouvre les ports mappÃ©s sur toutes les interfaces. Avec un pare-feu, vous pouvez restreindre lâ€™accÃ¨s Ã  certains services Ã  une IP de confiance ou Ã  un rÃ©seau interne.
- **Docker daemon** : ProtÃ©gez lâ€™accÃ¨s au socket Docker (`/var/run/docker.sock`). Ce socket donne un contrÃ´le total sur Docker (et donc sur la machine). Par dÃ©faut, seul root (ou le groupe docker) y a accÃ¨s â€“ ne mettez que des utilisateurs de confiance dans le groupe docker. Nâ€™exposez surtout pas lâ€™API Docker en TCP sans des mesures de sÃ©curitÃ©s robustes (certificats TLS client/serveur) â€“ sinon un attaquant pourrait prendre le contrÃ´le de votre hÃ´te via Docker.
- **Scanning de vulnÃ©rabilitÃ©s** : Envisagez dâ€™utiliser des outils dâ€™analyse dâ€™images (Docker fournit `docker scan`, basÃ© sur Snyk, pour dÃ©tecter les vulnÃ©rabilitÃ©s connues dans les images). Cela vous aide Ã  identifier des dÃ©pendances ou packages Ã  risque dans vos images, afin de les mettre Ã  jour.
- **Secrets** : Ne stockez pas de secrets (mots de passe, clÃ©s privÃ©es) en clair dans vos images ou variables dâ€™environnement. PrÃ©fÃ©rez les injecter au runtime via des fichiers montÃ©s (volumes) ou utilisez des solutions de gestion de secrets intÃ©grÃ©es (Docker Swarm et Kubernetes ont des objets *secrets* spÃ©cialisÃ©s pour cela). Au minimum, si vous devez passer un secret en variable, utilisez par exemple un fichier `.env` non versionnÃ© lu par Compose, plutÃ´t que de le commit dans un repo.

En suivant ces prÃ©cautions, vous rÃ©duisez considÃ©rablement la surface dâ€™attaque de vos conteneurs. Docker, bien configurÃ©, peut offrir une isolation proche de celle de VMs traditionnell ([Docker, c'est quoi ?](https://www.redhat.com/fr/topics/containers/what-is-docker#:~:text=une%20br%C3%A8che%20de%20s%C3%A9curit%C3%A9,mieux%20isol%C3%A9es%20du%20syst%C3%A8me%20h%C3%B4te))4ã€‘, mais cela requiert de respecter ces bonnes pratiques de durcissement.

### 7.2 Bonnes pratiques de dÃ©ploiement

Au-delÃ  de la sÃ©curitÃ©, voici dâ€™autres conseils pour opÃ©rer vos conteneurs en production de maniÃ¨re fiable :

- **Utiliser des orchestrateurs ou outils de gestion** : Sur un simple VPS, Docker Compose peut trÃ¨s bien gÃ©rer le dÃ©marrage de vos conteneurs. Mais pour plusieurs serveurs ou des besoins de scaling auto, envisagez un orchestrateur comme Kubernetes (voir chapitre 9) ou Docker Swarm. Ils apportent des fonctionnalitÃ©s de tolÃ©rance aux pannes et de dÃ©ploiements progressifs. MÃªme sur un seul nÅ“ud, des outils comme **Portainer** (interface web de gestion Docker) peuvent vous aider Ã  visualiser et administrer vos conteneurs.
- **Politique de redÃ©marrage** : Mettez `--restart=always` (ou dans Compose, `restart: always`) pour les conteneurs critiques afin quâ€™ils redÃ©marrent automatiquement en cas de crash ou au reboot du serveur Docker. Ainsi, si votre VPS redÃ©marre, vos services Docker se relanceront dâ€™eux-mÃªmes.
- **Limitation des ressources** : En production, Ã©vitez quâ€™un conteneur monopolise toute la machine. Utilisez les options `--memory`, `--cpus` pour limiter la RAM et CPU utilisables par conteneur. Par exemple `--memory=512m` pour contraindre Ã  512 Mo. Ceci Ã©vitera quâ€™un bug ou une charge soudaine saturent lâ€™hÃ´te et impactent les autres services.
- **Surveillance de la santÃ© (healthchecks)** : Vous pouvez dÃ©finir des commandes de **healthcheck** dans le Dockerfile (instruction HEALTHCHECK) pour que Docker surveille lâ€™application Ã  lâ€™intÃ©rieur du conteneur (par ex. ping dâ€™une URL de santÃ©). Compose/Kubernetes peuvent utiliser ces healthchecks pour redÃ©marrer un conteneur qui ne rÃ©pond plus correctement. Câ€™est utile pour dÃ©tecter automatiquement un service bloquÃ©.
- **Gestion des configs** : Pour vos applications, utilisez des variables dâ€™environnement ou des fichiers de configuration externes (montÃ©s en volume) pour adapter lâ€™application Ã  lâ€™environnement (dev, prod). Ainsi, vous nâ€™avez pas besoin de reconstruire une image pour changer une URL de base de donnÃ©es ou un niveau de log â€“ il suffit de changer la variable au dÃ©ploiement.
- **Mises Ã  jour sans coupure** : Ã‰tudiez des stratÃ©gies de dÃ©ploiement *rolling*. Par exemple, sur Kubernetes, un Deployment permet de faire un *rolling update* (on lance la nouvelle version et on arrÃªte progressivement lâ€™ancienne). Sur un single VPS sans orchestrateur, vous pourriez utiliser Compose en combinant des techniques comme dÃ©ployer une nouvelle instance et basculer un proxy. Lâ€™idÃ©e est dâ€™Ã©viter lâ€™indisponibilitÃ© : ne pas stopper tous les conteneurs avant dâ€™avoir les nouveaux prÃªts. Cela peut nÃ©cessiter une infrastructure un peu plus complexe (load balancer, etc.), mais câ€™est un objectif Ã  viser pour des services en production critiques.
- **Sauvegardes** : Nâ€™oubliez pas que si vous stockez des donnÃ©es dans des volumes Docker (ex: base de donnÃ©es), il faut les sauvegarder rÃ©guliÃ¨rement. Docker ne sâ€™en occupe pas. Vous pouvez soit faire des backups depuis lâ€™application (ex: dump SQL rÃ©gulier), soit monter vos volumes de donnÃ©es sur lâ€™hÃ´te et inclure ces dossiers dans vos procÃ©dures de sauvegarde du serveur.
- **Isolation par projet** : Si plusieurs applications tournent sur le mÃªme serveur Docker, isolez-les dans des networks distincts et utilisez des prÃ©fixes/nommage clairs pour les conteneurs, images et volumes (Compose le fait par projet). Ã‰vitez que deux projets utilisent un mÃªme nom de conteneur ou volume par inadvertance.

En appliquant ces bonnes pratiques, vous rendez votre dÃ©ploiement Docker plus robuste et plus facile Ã  maintenir sur le long terme.

### 7.3 Logs et monitoring des conteneurs

En production, pouvoir consulter les **logs** de vos applications et surveiller leur **mÃ©triques** (CPU, RAM, etc.) est indispensable pour dÃ©tecter les anomalies et diagnostiquer les problÃ¨mes.

**Gestion des logs :** Par dÃ©faut, Docker stocke les sorties standard (stdout/stderr) de chaque conteneur dans un fichier JSON (par conteneur) sous `/var/lib/docker/containers/<id>/<id>-json.log`. Câ€™est ce que `docker logs` affiche. Sur un serveur, ces fichiers peuvent grossir indÃ©finiment si lâ€™application est verbeuse. Pensez Ã  configurer une **rotation des logs**. Docker permet via son dÃ©mon dâ€™utiliser des drivers de logs (ex: `json-file` avec options de rotation, ou `syslog`, `journald`, etc.). Vous pouvez, dans `/etc/docker/daemon.json`, dÃ©finir par exemple :
```json
{"log-driver": "json-file", "log-opts": {"max-size": "10m", "max-file": "3"}}
``` 
pour limiter chaque log de conteneur Ã  10 Mo et garder 3 fichiers (rotation). Ainsi, pas de disque saturÃ©.

Pour une approche plus centralisÃ©e : envisagez dâ€™utiliser un systÃ¨me de collecte de logs :
- *Solution ELK (Elasticsearch + Logstash + Kibana)* ou sa variante lÃ©gÃ¨re EFK (Elasticsearch/Fluentd/Kibana) : vous pouvez dÃ©ployer un agent (Logstash/Fluentd) sur lâ€™hÃ´te Docker qui capte les logs des conteneurs (via le socket ou en lisant les fichiers) et les envoie vers une base centralisÃ©e (Elasticsearch) oÃ¹ vous pouvez les analyser avec Kibana.
- Des services cloud existent Ã©galement (Datadog, Splunk, etc.) ou des solutions comme Grafana Loki.

Lâ€™important est de ne pas perdre les logs et de pouvoir y accÃ©der mÃªme si un conteneur est mort ou a Ã©tÃ© recrÃ©Ã©. Au minimum, assurez-vous de sauvegarder les logs applicatifs critiques en dehors du conteneur (par ex, montÃ©s sur un volume host, ou redirigÃ©s vers syslog host).

**Monitoring des conteneurs :** Docker fournit la commande `docker stats` pour voir en temps rÃ©el la consommation CPU, mÃ©moire, E/S de vos conteneurs. En production automatisÃ©e, vous voudrez une solution plus robuste :
- **cAdvisor** (Container Advisor) : un outil open-source crÃ©Ã© par Google qui tourne en conteneur et collecte les mÃ©triques de tous les conteneurs Docker dâ€™un hÃ´te (CPU, mÃ©moire, network, filesystem...). Il expose ces mÃ©triques, que lâ€™on peut rÃ©colter via **Prometheus** (solution de monitoring open-source trÃ¨s utilisÃ©e pour containers et Kubernetes). Avec cAdvisor + Prometheus + Grafana, on peut avoir des tableaux de bord dÃ©taillÃ©s sur la santÃ© de chaque conteneur.
- **Docker Dashboard** : Docker Desktop propose un petit dashboard de ressources mais sur un serveur Linux sans interface, ce nâ€™est pas disponible.
- **Outils Cloud/APM** : Des solutions comme Datadog, NewRelic, etc., offrent des agents Docker pour remonter les mÃ©triques et parfois tracer les requÃªtes Ã  travers les conteneurs.

**Alerting** : Pensez Ã  mettre en place des alertes sur les mÃ©triques importantes : par exemple, si un conteneur consomme plus de 90% CPU sur 5 minutes, ou si la mÃ©moire libre de lâ€™hÃ´te passe sous un seuil, etc. Ceci vous permettra dâ€™intervenir avant une panne. Prometheus/Grafana ou des services SaaS peuvent envoyer des alertes email/Slack.

En complÃ©ment, surveillez lâ€™Ã©tat de Docker lui-mÃªme. Assurez-vous que le daemon Docker tourne (par dÃ©faut en service systemd, il redÃ©marre tout seul en cas de crash). Surveillez lâ€™espace disque de `/var/lib/docker` (images et volumes peuvent remplir le disque â€“ faites du nettoyage dâ€™images obsolÃ¨tes avec `docker system prune` de temps en temps, ou expansion de stockage si nÃ©cessaire).

Pour finir, loggez aussi lâ€™activitÃ© Docker en elle-mÃªme : les actions de dÃ©ploiement, etc., afin dâ€™auditer qui a lancÃ© quoi (sur un serveur multi-admin). Docker conserve un log (souvent via journald ou /var/log/docker.log suivant config) que vous pouvez consulter.

En rÃ©sumÃ©, une stack de production typique pourrait inclure :
- Un **systÃ¨me de logs centralisÃ©s** (par exemple Filebeat/Logstash + Elasticsearch + Kibana) pour agrÃ©ger les logs de tous les conteneurs.
- Un **systÃ¨me de monitoring** (Prometheus + Grafana) scrutant les mÃ©triques dâ€™infrastructure (Docker, OS) et Ã©ventuellement instrumentant les applications (via exporters ou APM).
- Des **alertes** pour rÃ©agir en cas dâ€™incident (conteneur down, utilisation anormale, etc.).

Avec Docker, beaucoup de choses sont Ã©phÃ©mÃ¨res, il faut donc Ãªtre particuliÃ¨rement attentif Ã  ne pas perdre lâ€™information en route. Un conteneur qui crash et disparaÃ®t doit laisser derriÃ¨re lui au moins un log dâ€™erreur dans votre systÃ¨me centralisÃ©, sans quoi le diagnostic sera compliquÃ©.

## 8. CI/CD avec Docker

La conteneurisation sâ€™intÃ¨gre parfaitement aux chaÃ®nes dâ€™intÃ©gration continue et de dÃ©ploiement continu (**CI/CD**). Docker permet de construire une image de votre application Ã  chaque changement de code et de la dÃ©ployer de maniÃ¨re consistante sur vos diffÃ©rents environnements. Dans cette section, nous verrons comment Docker sâ€™intÃ¨gre avec des pipelines CI/CD tels que **GitHub Actions** ou **GitLab CI**, et comment automatiser la construction et le dÃ©ploiement de vos conteneurs.

### 8.1 IntÃ©gration de Docker dans la CI

Sans Docker, une pipeline CI classique doit installer toutes les dÃ©pendances de lâ€™application sur lâ€™agent CI avant de lancer les tests ou le dÃ©ploiement, ce qui peut Ãªtre lent et sujet Ã  des problÃ¨mes (versions dâ€™outils diffÃ©rentes, etc.). Avec Docker, on peut au contraire :
- Soit utiliser **Docker pour exÃ©cuter les Ã©tapes CI** : par exemple, exÃ©cuter les tests de lâ€™application Ã  lâ€™intÃ©rieur dâ€™un conteneur configurÃ© identiquement Ã  lâ€™environnement de prod. GitHub Actions et GitLab CI permettent de lancer des conteneurs Docker dans les jobs, garantissant que Â« Ã§a marche pareil que sur ma machine Â».
- Soit (et surtout) **construire lâ€™image Docker** de lâ€™application dans le pipeline CI, et Ã©ventuellement la pousser dans un registre. Cela permet de versionner chaque build (ex: taggÃ© avec le commit ou un numÃ©ro de version), et de dÃ©ployer exactement cette image en production.

Lâ€™idÃ©e typique : Ã  chaque push sur la branche main (ou crÃ©ation dâ€™une release), la CI va :
1. Builder lâ€™image Docker de lâ€™application (`docker build`).
2. Lâ€™exÃ©cuter et lancer les tests unitaires Ã  lâ€™intÃ©rieur (ou utiliser un conteneur sÃ©parÃ© pour les tests, dÃ©pendant de la stratÃ©gie).
3. Si tests ok, pousser lâ€™image vers un registre (Docker Hub, GitLab Registry, ECR AWS, etc.).
4. DÃ©clencher le dÃ©ploiement : par exemple, informer un serveur de rÃ©cupÃ©rer la nouvelle image et de relancer un conteneur, ou crÃ©er une release sur Kubernetes.

Les systÃ¨mes CI/CD modernes (GitHub Actions, GitLab CI, Jenkins, etc.) ont de trÃ¨s bons supports de Docker.

### 8.2 Exemple avec GitHub Actions

GitHub Actions permet de dÃ©finir des workflows dâ€™intÃ©gration et dÃ©ploiement via un fichier YAML (dans `.github/workflows/`). Voici un exemple simple de pipeline CI/CD qui build et push une image Docker :

```yaml
name: CI Build and Push
on:
  push:
    branches: [ main ]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3  # RÃ©cupÃ©rer le code du dÃ©pÃ´t
      - name: Build Docker image
        run: docker build -t monutilisateur/monapp:${{ github.sha }} .
      - name: Login to Docker Hub
        env:
          DOCKER_USER: ${{ secrets.DOCKER_USER }}
          DOCKER_PASS: ${{ secrets.DOCKER_PASS }}
        run: echo "$DOCKER_PASS" \| docker login -u "$DOCKER_USER" --password-stdin
      - name: Push image to registry
        run: docker push monutilisateur/monapp:${{ github.sha }}
```

Explication :
- Ce workflow se dÃ©clenche Ã  chaque push sur la branche main.
- Lâ€™environnement dâ€™exÃ©cution est une VM Ubuntu Ã©quipÃ©e de Docker.
- On checkoute le code, puis on exÃ©cute `docker build` pour construire lâ€™image, en la taguant avec lâ€™identifiant du commit (`github.sha` fournit le SHA du commit). On pourrait tagguer `latest` ou une version, mais utiliser le SHA garantit lâ€™unicitÃ©.
- Ensuite, on se logge Ã  Docker Hub (`docker login`) en utilisant des secrets stockÃ©s dans GitHub (il faut dÃ©finir DOCKER_USER/PASS dans la configuration du repo GitHub).
- Enfin, on pousse lâ€™image. Ainsi, Ã  chaque modification, on aura sur Docker Hub une image Ã  jour (taggÃ©e par son SHA ou on pourrait aussi tagger `latest` en plus pour la derniÃ¨re version).

On pourrait enrichir ce workflow en ajoutant un job de tests (par exemple, *builder* lâ€™image, puis *run* un conteneur de test ou utiliser `docker run` pour exÃ©cuter une suite de tests Ã  lâ€™intÃ©rieur, ou utiliser un service DB Ã  cÃ´tÃ© pendant les tests). GitHub Actions permet dâ€™utiliser des *services* (un peu comme Compose) ou de lancer plusieurs conteneurs.

### 8.3 Exemple avec GitLab CI/CD

Avec **GitLab CI**, lâ€™idÃ©e est similaire. GitLab fournit un registre dâ€™images intÃ©grÃ© (Container Registry) par projet. Un runner GitLab peut utiliser Docker dâ€™une faÃ§on particuliÃ¨re : souvent via **Docker-in-Docker (DinD)**. On active un service Docker dans le job pour pouvoir lancer des commandes Docker.

Un `.gitlab-ci.yml` simple pourrait Ãªtre :
```yaml
image: docker:20.10  # image Docker CLI
services:
  - docker:dind     # service Docker Daemon

build:
  stage: build
  script:
    - docker build -t registry.gitlab.com/monprojet/monapp:$CI_COMMIT_SHA .
    - echo "$CI_REGISTRY_PASSWORD" \| docker login -u "$CI_REGISTRY_USER" $CI_REGISTRY --password-stdin
    - docker push registry.gitlab.com/monprojet/monapp:$CI_COMMIT_SHA
```

Ici on utilise lâ€™image Docker officielle pour avoir la CLI, et on utilise le service `docker:dind` (un conteneur Docker Engine dans lequel la CLI va se connecter). On build puis on push sur le registry du projet (les variables CI_REGISTRY_USER/PASSWORD sont fournies automatiquement pour le registre GitLab). Le principe reste le mÃªme : produire lâ€™image et la stocker.

**DÃ©ploiement continu :** Une fois lâ€™image poussÃ©e, la phase CD (dÃ©ploiement) peut prendre le relais. Selon votre infrastructure, cela peut Ãªtre :
- Sur un serveur Docker classique : utiliser **SSH** pour se connecter au serveur et exÃ©cuter `docker pull` puis `docker-compose up -d` avec la nouvelle image, par exemple. GitHub Actions/GitLab CI peuvent faire du SSH sur un hÃ´te pour dÃ©ployer.
- Sur Kubernetes : on peut utiliser kubectl dans le pipeline (par ex. un job qui applique un manifeste Kubernetes mis Ã  jour avec le nouveau tag dâ€™image, ou qui utilise un dÃ©ploiement auto-trigger).
- Via des outils spÃ©cialisÃ©s : par ex, utiliser Argo CD (GitOps) ou Helm charts dÃ©ployÃ©s via pipeline. Ou les GitLab *Environments* et *Deploy Boards* si on utilise Kubernetes.

Lâ€™important est que, grÃ¢ce Ã  Docker, votre artefact de dÃ©ploiement est lâ€™image elle-mÃªme. Une fois quâ€™elle est testÃ©e et poussÃ©e, la mÃªme image est dÃ©ployÃ©e en prod, Ã©vitant tout Ã©cart entre environnements. Vous pouvez tagger lâ€™image avec le numÃ©ro de version ou le tag Git (ex: `1.2.3` ou `release-2023-03`) pour vous y retrouver.

**IntÃ©gration de tests dans des conteneurs :** Un autre usage de Docker en CI est de lancer les tests dans un environnement Ã©phÃ©mÃ¨re reproductible. Par exemple, on peut avoir un job qui fait `docker-compose -f docker-compose.test.yml up --abort-on-container-exit` pour exÃ©cuter une suite de tests intÃ©gration (en montant du code ou en construisant une image test dÃ©diÃ©e) â€“ Ã  la fin, Compose arrÃªte tout. Cela permet de tester votre application conteneurisÃ©e comme elle le serait en vrai.

En somme, Docker et la CI/CD vont de pair. En automatisant la construction dâ€™images et leur dÃ©ploiement, on obtient un flux de dÃ©ploiement trÃ¨s rapide : un dÃ©veloppeur pousse du code -> quelques minutes plus tard, une nouvelle image est construite et dÃ©ployÃ©e sur un environnement (staging ou production) de maniÃ¨re consistante. Cette approche Ã©limine beaucoup de problÃ¨mes de Â« configuration drift Â» et de Â« works on my machine Â», car tout est contenu dans lâ€™image Docker crÃ©Ã©e par la CI.

## 9. Introduction Ã  Kubernetes

Lorsque vos dÃ©ploiements dâ€™applications conteneurisÃ©es deviennent plus complexes (beaucoup de conteneurs, besoin de haute disponibilitÃ©, multi-nÅ“udsâ€¦), il est temps de passer Ã  lâ€™**orchestration de conteneurs**. **Kubernetes** (souvent notÃ© *K8s*) est la plateforme open-source la plus rÃ©pandue pour automatiser le dÃ©ploiement, la montÃ©e en charge et la gestion de conteneurs sur un cluster de machin ([Kubernetes â€” WikipÃ©dia](https://fr.wikipedia.org/wiki/Kubernetes#:~:text=Kubernetes%20%28commun%C3%A9ment%20appel%C3%A9%20%C2%AB%C2%A0K8s,la%20Cloud%20Native%20Computing%20Foundation))9ã€‘. Dans ce chapitre, nous allons introduire les concepts clÃ©s de Kubernetes â€“ en particulier les objets **Pods**, **Deployments** et **Services** â€“ et voir comment installer un cluster de test, ainsi que les bases de la gestion de charges de travail conteneurisÃ©es avec K8s.

### 9.1 Concepts clÃ©s de Kubernetes

**Cluster Kubernetes :** Kubernetes fonctionne sur un ensemble de machines (physiques ou virtuelles) formant un cluster. Un cluster K8s se compose gÃ©nÃ©ralement de *nÅ“uds de calcul* (workers) qui exÃ©cutent les conteneurs, et de composants de *plan de contrÃ´le* (control plane) qui gÃ¨rent lâ€™orchestration (API server, scheduler, contrÃ´leurs, etc.). Kubernetes abstrait ces machines pour que vous dÃ©ployiez vos applications sans vous soucier du dÃ©tail de quel nÅ“ud individuel les exÃ©cute.

Les objets fondamentaux de Kubernetes pour dÃ©crire et gÃ©rer une application conteneurisÃ©e sont :

- **Pod** : lâ€™unitÃ© de base de Kubernetes. Un Pod est le plus petit objet dÃ©ployable dans Kubernet ([Pods | Kubernetes](https://kubernetes.io/fr/docs/concepts/workloads/pods/pod/#:~:text=Les%20Pods%20sont%20les%20plus,cr%C3%A9%C3%A9es%20et%20g%C3%A9r%C3%A9es%20dans%20Kubernetes))4ã€‘. Il encapsule un ou plusieurs conteneurs qui partagent un mÃªme espace rÃ©seau et de stockage. Dans la majoritÃ© des cas, un Pod contient un seul conteneur applicatif principal (Ã©ventuellement accompagnÃ© de conteneurs auxiliaires appelÃ©s *sidecars*). Si vous dÃ©ployez un microservice, il sera gÃ©nÃ©ralement packagÃ© dans un Pod = 1 conteneur. Kubernetes crÃ©e, supervise et termine des Pods, pas directement des conteneurs individuels.
- **Deployment (DÃ©ploiement)** : un contrÃ´leur dâ€™abstraction qui gÃ¨re un ensemble de pods identiques (rÃ©plicas) et permet des mises Ã  jour dÃ©clarativ ([DÃ©ploiements | Kubernetes](https://kubernetes.io/fr/docs/concepts/workloads/controllers/deployment/#:~:text=Un%20Deployment%20,d%C3%A9claratives%20pour%20Pods%20et%20ReplicaSets))4ã€‘. Avec un Deployment, vous dÃ©clarez dans un manifeste YAML lâ€™*Ã©tat dÃ©sirÃ©* de votre application (par exemple : Â« je veux 3 instances du pod *webapp*, tournant avec lâ€™image *myapp:v1* Â»). Kubernetes se charge de crÃ©er ces pods (en arriÃ¨re-plan, un Deployment gÃ¨re un ReplicaSet qui lui-mÃªme gÃ¨re les pods). Si un pod meurt, le Deployment en recrÃ©e un pour maintenir le nombre souhaitÃ©. Si vous voulez dÃ©ployer une nouvelle version, vous modifiez le Deployment (par ex. nouvelle image *v2*), Kubernetes va orchestrer le remplacement graduel des pods (câ€™est le rolling update).
- **Service** : une abstraction rÃ©seau pour exposer vos po ([Service | Kubernetes](https://kubernetes.io/fr/docs/concepts/services-networking/service/#:~:text=Service))6ã€‘. Un Service dÃ©finit un ensemble logique de pods (par un *selector* sur des labels) et fournit une adresse stable pour y accÃ©der. Les pods peuvent changer (par ex, tuÃ©s et recrÃ©Ã©s, donc avec nouvelles IPs), mais le Service reste en place pour les clients. Il existe plusieurs types de Services : 
  - *ClusterIP* (par dÃ©faut) : expose les pods Ã  une IP interne du cluster (accessible seulement depuis le cluster, par dâ€™autres pods).
  - *NodePort* : expose le service sur un port fixÃ© de chaque nÅ“ud du cluster, ce qui permet dâ€™y accÃ©der de lâ€™extÃ©rieur en visant nâ€™importe quel nÅ“ud Ã  ce port.
  - *LoadBalancer* : rÃ©servÃ© gÃ©nÃ©ralement aux clusters dans le cloud, ce type demande Ã  lâ€™infrastructure cloud de provisionner un load balancer externe (par ex. un ELB sur AWS) pointant vers les pods. 
  - (Et dâ€™autres comme ExternalName, etc.) 
  Un Service agit un peu comme un DNS + load balancer interne : il attribue un nom DNS stable et distribue le trafic vers les pods en backend.

Pour identifier les pods, Kubernetes utilise des **labels** (Ã©tiquettes clÃ©=valeur) que vous pouvez attacher aux objets et sur lesquels les Service ou Deployments sâ€™appuient (ex: Deployment va donner un label `app: webapp` Ã  ses pods, et le Service va cibler `app: webapp` pour faire le lien).

Par exemple, on pourrait avoir : un Deployment nommÃ© *webapp-deployment* qui gÃ¨re des pods labelisÃ©s `app=webapp`. Un Service *webapp-service* selectionne `app=webapp` et Ã©coute sur le port 80, rÃ©partissant les requÃªtes aux pods. Si on scale le Deployment Ã  5 pods, le Service enverra le trafic aux 5.

En plus de ces objets, Kubernetes en comporte beaucoup dâ€™autres (ConfigMap pour les configs, Secret pour les secrets, Ingress pour la gestion fine du trafic HTTP, StatefulSet pour les applications Ã  Ã©tat comme bases de donnÃ©es, DaemonSet, Job/CronJob, etc.). Mais Pod, Deployment et Service sont vraiment le trio de base pour nâ€™importe quelle application sans Ã©tat (stateless app).

### 9.2 Installation dâ€™un cluster Kubernetes (pour tests)

Mettre en place Kubernetes peut Ãªtre complexe (surtout sur plusieurs nÅ“uds), mais il existe des solutions simples pour tester en local :
- **Minikube** : un outil qui installe un cluster Kubernetes monoposte dans une VM sur votre machine. En une commande `minikube start`, vous avez un petit cluster fonctionnel (un seul nÅ“ud faisant office de control plane et worker).
- **Docker Desktop** : intÃ¨gre une option "Enable Kubernetes". En lâ€™activant, Docker Desktop dÃ©marre un Kubernetes mono-noeud dans votre environnement Docker. Pratique pour les tests rapides (pas besoin dâ€™installer autre chose).
- **Kind** (Kubernetes-in-Docker) : lance un cluster Kubernetes en exÃ©cutant les nÅ“uds control plane et worker eux-mÃªmes comme conteneurs Docker. Câ€™est lÃ©ger et scriptable.
- **MicroK8s** : distribution Kubernetes allÃ©gÃ©e proposÃ©e par Canonical (Ubuntu) pour un usage local ou edge, sâ€™installe via snap sur Linux.

Pour un usage sÃ©rieux en production, on utilise souvent des **services managÃ©s** (GKE sur Google Cloud, EKS sur AWS, AKS sur Azure, etc.) ou des distributions comme kubeadm, Rancher, K3s, etc. Sur un VPS, vous pourriez installer Kubernetes via **kubeadm** : câ€™est lâ€™outil officiel pour dÃ©ployer un cluster : on promeut un serveur en master, puis on join dâ€™autres serveurs comme workers. Cependant, câ€™est assez impliquÃ© (certificats, rÃ©seaux Ã  configurer, etc.). Si vous voulez expÃ©rimenter sur 2-3 VMs, kubeadm est un bon apprentissage, mais pour un dÃ©butant, minikube est plus simple.

**Installer Minikube (bref aperÃ§u) :**
- Avoir Docker ou une solution de VM (VirtualBox par ex) sur votre machine.
- TÃ©lÃ©charger lâ€™exÃ©cutable minikube.
- Faire `minikube start` â€“ Ã§a va crÃ©er une VM Linux et y dÃ©ployer Kubernetes.
- minikube configure automatiquement `kubectl` (le client en ligne de commande de Kubernetes) pour pointer vers ce cluster.

Une fois minikube dÃ©marrÃ©, vous pouvez utiliser `kubectl get nodes` pour voir le nÅ“ud, etc. Le kubectl est lâ€™outil principal pour interagir avec Kubernetes.

### 9.3 Gestion des workloads sur Kubernetes

DÃ©ployer une application sur Kubernetes consiste gÃ©nÃ©ralement Ã  **Ã©crire des fichiers YAML** dÃ©crivant les objets (Deployment, Service, etc.), puis Ã  les appliquer au cluster via `kubectl apply -f mondeploiement.yaml`.

Par exemple, un manifeste YAML de Deployment minimal pour notre application web pourrait Ãªtre :
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp
  template:   # spÃ©cification des pods
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp-container
        image: monutilisateur/monapp:1.0
        ports:
        - containerPort: 3000
```
Ici on demande 3 replicas de `monutilisateur/monapp:1.0`. Kubernetes va donc dÃ©marrer 3 pods contenant chacun ce conteneur. Si on fait `kubectl get pods`, on verra 3 pods (nommÃ©s automatiquement *webapp-deployment-xxxxx*). 

On exposerait cela avec un Service, par exemple :
```yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
spec:
  type: NodePort
  selector:
    app: webapp
  ports:
    - port: 3000       # port interne du service (cible des pods)
      targetPort: 3000 # port exposÃ© par les pods
      nodePort: 30000  # port sur les nodes
```
Ce Service prendra tous les pods avec `app=webapp` (donc nos 3 pods) et les rendra accessibles sur chaque machine du cluster via le port 30000. Sur minikube (un seul node), on pourrait ainsi accÃ©der Ã  `http://<IP_minikube>:30000` pour joindre lâ€™application.

**Commande kubectl de base :** 
- `kubectl get pods,deploy,svc` pour lister les ressources.
- `kubectl describe pod <name>` pour obtenir les dÃ©tails et Ã©vÃ©nements dâ€™un pod (prÃ©cieux en cas dâ€™erreur de dÃ©marrage).
- `kubectl logs <pod>` pour voir les logs (on peut ajouter `-f` ou `-c nom_du_containeur` si plusieurs conteneurs dans un pod).
- `kubectl exec -it <pod> -- bash` pour entrer dans un conteneur du pod (similaire Ã  `docker exec`).
- `kubectl scale deployment/webapp-deployment --replicas=5` pour changer le nombre de replicas.
- `kubectl rollout status deployment/webapp-deployment` pour voir la progression dâ€™un dÃ©ploiement (par ex, lors dâ€™une mise Ã  jour).
- `kubectl apply -f fichier.yaml` pour crÃ©er ou mettre Ã  jour des objets via un fichier.
- `kubectl delete -f fichier.yaml` pour supprimer ce qui est dÃ©crit dans le fichier, ou `kubectl delete pod/nom` etc. pour un objet spÃ©cifique.

**Auto-rÃ©paration et scaling :** Kubernetes va surveiller les pods : si un nÅ“ud tombe en panne, les pods qui y tournaient sont reprogrammÃ©s ailleurs (si dâ€™autres nÅ“uds dispos). Le Deployment sâ€™assure toujours dâ€™avoir le bon nombre de pods vivants. On peut configurer des **probes de santÃ©** (livenessProbe, readinessProbe) dans la spec du conteneur pour que Kubernetes sache dÃ©tecter un conteneur plantÃ© (liveness) ou pas encore prÃªt Ã  recevoir du trafic (readiness). En fonction, Kubernetes peut redÃ©marrer le conteneur ou lâ€™isoler du Service temporairement.

K8s offre aussi le **Horizontal Pod Autoscaler (HPA)**, qui peut augmenter/diminuer le nombre de pods en fonction de la charge (par ex., si CPU > 80% sur 5 min, ajouter des pods). Pour cela, il faut avoir des mÃ©triques (via Metrics Server). Câ€™est un sujet un peu avancÃ©, mais sachez que la scalabilitÃ© horizontale peut Ãªtre automatique.

**Mises Ã  jour** : Avec un Deployment, un changement dâ€™image ou de configuration dÃ©clenche un *rolling update* par dÃ©faut : K8s va crÃ©er un nouveau pod (avec la nouvelle version) avant de supprimer un ancien, et ainsi de suite, assurant quâ€™Ã  tout moment il reste des pods pour servir. Vous pouvez ajuster la stratÃ©gie (max pods en plus/en moins, etc.). En cas de problÃ¨me, vous pouvez faire un *rollback* du dÃ©ploiement Ã  la version prÃ©cÃ©dente trÃ¨s facilement (`kubectl rollout undo deployment/webapp-deployment`).

**Organisation** : En pratique, on regroupe plusieurs objets dans des fichiers ou charts (Helm). Par exemple, un dÃ©ploiement complet dâ€™appli comprend souvent : Deployment, Service, Ingress (pour routage http), ConfigMap/Secret (pour la config), PersistentVolumeClaim (pour rÃ©server du stockage si base de donnÃ©es, dans le cas dâ€™un StatefulSet). Kubernetes a une courbe dâ€™apprentissage, mais une fois les concepts assimilÃ©s, il offre un contrÃ´le trÃ¨s fin et une grande fiabilitÃ© pour exÃ©cuter des conteneurs en prod.

Enfin, Kubernetes a son propre Ã©cosystÃ¨me dâ€™outils (kubectl Ã©tant de base). Des tableaux de bord web existent (Lens, le dashboard officiel K8s, etc.) pour visualiser les ressources. Et des opÃ©rateurs/contrÃ´leurs additionnels peuvent Ãªtre installÃ©s pour ajouter des fonctionnalitÃ©s (autoscaler de pods, gestion de certificats auto, etc.).

Pour un dÃ©butant, le plus gros dÃ©fi est de se familiariser avec la terminologie et la logique dÃ©clarative de Kubernetes. Commencez par dÃ©ployer une application simple sur minikube en suivant la documentation â€“ par exemple *Hello World* ou une app web comme la nÃ´tre â€“ et expÃ©rimentez les commandes kubectl.

*Kubernetes* est un vaste sujet, mais maÃ®triser Docker vous donne dÃ©jÃ  une base solide, car beaucoup de concepts (images, conteneurs, ports, volumes) restent valables. Kubernetes se charge juste de lancer les conteneurs sur un cluster de machines de faÃ§on intelligente. En rÃ©sumÃ©, comme le dit souvent la communautÃ© : Docker vous permet dâ€™exÃ©cuter un conteneur sur *votre* machine, Kubernetes vous permet dâ€™exÃ©cuter des conteneurs sur *des centaines* de machines de maniÃ¨re automatisÃ©e.

## 10. Ã‰tude de cas et projets pratiques

Pour terminer ce guide, illustrons de maniÃ¨re concrÃ¨te tout le parcours de dÃ©ploiement dâ€™une application web conteneurisÃ©e, depuis le dÃ©veloppement jusquâ€™Ã  la production orchestrÃ©e. Nous allons prendre lâ€™exemple dâ€™une application web simple composÃ©e de deux Ã©lÃ©ments : un frontend (notre application web) et une base de donnÃ©es MySQL. Lâ€™objectif est de montrer comment :

1. **Containeriser lâ€™application** avec Docker (Ã©crire un Dockerfile et construire lâ€™image).
2. **Configurer lâ€™environnement de dÃ©veloppement** avec Docker Compose (pour lancer lâ€™appli et la DB ensemble facilement en local).
3. **DÃ©ployer en production** en utilisant Kubernetes sur un cluster.

Imaginons que notre application soit un petit serveur web dÃ©veloppÃ© en Node.js qui stocke des donnÃ©es dans une base MySQL. Appelons-la *MyApp*. Voici les grandes Ã©tapes :

### 10.1 Conteneurisation de l'application web (Dockerfile)

Supposons que le code de *MyApp* est dans un rÃ©pertoire `myapp/` avec un fichier `package.json` (pour les dÃ©pendances Node) et un fichier dâ€™entrÃ©e `index.js`. La premiÃ¨re Ã©tape est dâ€™Ã©crire un **Dockerfile** pour emballer cette application Node.js dans une image.

Dockerfile (`myapp/Dockerfile`) :
```dockerfile
# Ã‰tape 1 : image de base Node.js
FROM node:18-alpine

# Ã‰tape 2 : dÃ©finir le rÃ©pertoire de l'application
WORKDIR /app

# Ã‰tape 3 : copier les fichiers de dÃ©pendances et installer
COPY package*.json ./
RUN npm install --production

# Ã‰tape 4 : copier le code de l'application
COPY . .

# Ã‰tape 5 : exposer le port d'Ã©coute de l'application (par ex 3000)
EXPOSE 3000

# Ã‰tape 6 : commande de dÃ©marrage
CMD ["node", "index.js"]
```

Explication rapide :
- On part de l'image Node.js officielle en version 18 (variante alpine pour la lÃ©gÃ¨retÃ©).
- On dÃ©finit le dossier de travail et on copie le fichier `package.json` et `package-lock.json` (le wildcard package*.json les couvre). Puis on lance `npm install` pour installer les dÃ©pendances nÃ©cessaires.
- On copie ensuite le reste du code.
- On expose le port 3000 (admettons que notre app Ã©coute sur 3000).
- On dÃ©finit la commande `node index.js` pour dÃ©marrer le serveur web.

Avec ce Dockerfile, on peut construire lâ€™image de notre application. Supposons que lâ€™on veuille la tagger `myapp:dev` pour indiquer que câ€™est lâ€™image de dÃ©veloppement (on utilisera un autre tag pour la production plus tard) :

```bash
# depuis le rÃ©pertoire myapp/
docker build -t myapp:dev .
```

Docker va produire lâ€™image locale `myapp:dev`. Testons-la rapidement (en la reliant Ã  une DB MySQL existante par exemple, si on en a une). Mais pour lâ€™instant, concentrons-nous sur l'intÃ©gration avec MySQL via Compose.

### 10.2 Environnement de dÃ©veloppement avec Docker Compose

Pour dÃ©velopper et tester *MyApp*, nous allons utiliser **Docker Compose** afin de lancer Ã  la fois lâ€™application Node (conteneur basÃ© sur lâ€™image quâ€™on vient de construire) et un conteneur MySQL pour la base de donnÃ©es. Lâ€™utilisation de Compose va nous simplifier la vie : un seul fichier pour configurer les deux, et une commande pour tout lancer.

CrÃ©ons un fichier `docker-compose.yml` Ã  la racine du projet :

```yaml
services:
  app:
    build: ./myapp   # construit l'image Ã  partir du Dockerfile dans myapp/
    ports:
      - "3000:3000"
    environment:
      - DB_HOST=db
      - DB_NAME=myappdb
      - DB_USER=root
      - DB_PASSWORD=example
    depends_on:
      - db

  db:
    image: mysql:8
    environment:
      - MYSQL_DATABASE=myappdb
      - MYSQL_ROOT_PASSWORD=example
    volumes:
      - db_data:/var/lib/mysql

volumes:
  db_data:
```

Dans ce fichier Compose :
- Le service **app** va construire lâ€™image Ã  partir du Dockerfile (option `build: ./myapp` pointant vers le dossier). On expose le port 3000 pour accÃ©der Ã  l'appli web depuis lâ€™hÃ´te. On dÃ©finit quelques variables dâ€™environnement que lâ€™application Node utilisera pour se connecter Ã  la DB (nom dâ€™hÃ´te du serveur DB, nom de la base, user, mot de passe). Ici, par simplicitÃ© on utilise lâ€™utilisateur root de MySQL avec un mot de passe (pas idÃ©al en prod, mais en dev Ã§a va). `depends_on: db` assure que le conteneur db soit dÃ©marrÃ© avant app.
- Le service **db** utilise lâ€™image MySQL 8. On passe `MYSQL_DATABASE` pour quâ€™une base `myappdb` soit crÃ©Ã©e dâ€™office, et `MYSQL_ROOT_PASSWORD` pour le mot de passe root (ici "example"). On monte un volume nommÃ© `db_data` pour persister les donnÃ©es MySQL (ainsi arrÃªter/relever Compose ne perd pas les donnÃ©es insÃ©rÃ©es).
- On a dÃ©clarÃ© le volume `db_data` Ã  la fin.

Pour lancer le tout, on exÃ©cute simplement :
```bash
docker-compose up -d
```
Compose va:
  - Construire lâ€™image *app* (Ã©quivalent Ã  notre `docker build` plus tÃ´t).
  - CrÃ©er le rÃ©seau `mon_projet_default` et le volume `db_data`.
  - DÃ©marrer le conteneur **db** (MySQL) puis **app** (MyApp). Le conteneur app verra la variable `DB_HOST=db`, et grÃ¢ce au rÃ©seau commun, le nom dâ€™hÃ´te `db` rÃ©soudra lâ€™adresse IP du conteneur MySQL.

AprÃ¨s quelques secondes, MySQL devrait Ãªtre opÃ©rationnel et *MyApp* peut sans doute se connecter (il faudra dans le code Node.js rÃ©cupÃ©rer ces variables dâ€™env et se connecter, par ex. en utilisant `process.env.DB_HOST`, etc.). Vous pouvez vÃ©rifier les logs :
```bash
docker-compose logs -f app
```
pour voir si lâ€™app Node a rÃ©ussi sa connexion. Vous pouvez aussi vous connecter Ã  MySQL pour vÃ©rifier que la base `myappdb` existe, par exemple en exÃ©cutant :
```bash
docker-compose exec db mysql -uroot -pexample -e "SHOW DATABASES;"
``` 
(qui utilisera le client mysql Ã  lâ€™intÃ©rieur du conteneur).

Si tout est bon, en ouvrant un navigateur sur http://localhost:3000, vous devriez accÃ©der Ã  l'application *MyApp*. Dans le cas dâ€™une API REST, on pourrait faire des requÃªtes avec curl. Lâ€™essentiel est quâ€™en quelques minutes, on a mis en place un environnement de dev isolÃ©, sans installer MySQL ou Node localement : tout tourne dans Docker. Chaque membre de lâ€™Ã©quipe pourrait lancer le mÃªme `docker-compose up` et obtenir un environnement identique.

Pendant la phase de dÃ©veloppement, on peut reconstruire lâ€™image app Ã  chaque modification du code, ou monter le code en volume pour recharger Ã  chaud (on aurait pu faire `volumes: - "./myapp:/app"` pour que les modifications locales soient vues dans le conteneur, couplÃ© avec un outil genre nodemon pour restart auto â€“ ceci est une amÃ©lioration possible du workflow de dev).

### 10.3 DÃ©ploiement de l'application sur Kubernetes (production)

Une fois lâ€™application testÃ©e et prÃªte, comment la dÃ©ployer en production sur un serveur ou cluster Kubernetes ?

**PrÃ©paration de lâ€™image de production :** 
Dâ€™abord, on peut reconstruire lâ€™image Node sans le tag *dev*. Ã‰ventuellement, on optimise le Dockerfile pour la prod (par ex, utiliser `NODE_ENV=production`, retirer dâ€™Ã©ventuelles dÃ©pendances de dev, etc.). Disons que lâ€™on construit et tague lâ€™image comme `monutilisateur/monapp:1.0` et quâ€™on la pousse sur Docker Hub (ou un registre privÃ©). Cette Ã©tape peut Ãªtre faite via CI/CD comme dÃ©crit prÃ©cÃ©demment.

**Base de donnÃ©es en production :** 
Plusieurs approches :
- Utiliser Ã©galement un conteneur MySQL sur le cluster K8s. Kubernetes sait gÃ©rer du stockage persistant via des PersistentVolumeClaim. On pourrait dÃ©ployer MySQL dans un *StatefulSet* avec un volume persistant (ce qui assure que les donnÃ©es survivent aux recrÃ©ations de pod). Câ€™est faisable, bien que pour des bases critiques en production, on utilise parfois un service gÃ©rÃ© (RDS, Cloud SQL...) ou on la garde hors cluster.
- Pour notre cas, on va continuer avec MySQL conteneurisÃ©, pour garder lâ€™Ã©tude homogÃ¨ne.

**DÃ©ploiement Kubernetes :** 
Nous allons crÃ©er un Deployment pour *MyApp* et un Deployment (ou StatefulSet) pour MySQL, plus les Services nÃ©cessaires.

CommenÃ§ons par le **Deployment de MyApp** (fichier `k8s-myapp-deployment.yaml`) :
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: monutilisateur/monapp:1.0
        env:
        - name: DB_HOST
          value: "mysql"               # on supposera un Service "mysql" pour la DB
        - name: DB_NAME
          value: "myappdb"
        - name: DB_USER
          value: "root"
        - name: DB_PASSWORD
          value: "example"
        ports:
        - containerPort: 3000
```

Ici, on dÃ©ploie 2 replicas de lâ€™app (on peut en mettre plus pour rÃ©partir la charge). On passe les mÃªmes variables dâ€™env quâ€™avant, en particulier `DB_HOST=mysql` â€“ cela signifie quâ€™on sâ€™attend Ã  avoir un Service DNS nommÃ© "mysql" dans le namespace. On expose le port 3000 du conteneur (note: cela aide Kubernetes Ã  savoir quel port est *targetPort* par dÃ©faut pour un Service le sÃ©lectionnant).

Ensuite, le **Deployment (ou StatefulSet) pour MySQL** (`k8s-mysql-deployment.yaml`). Pour simplifier, utilisons un Deployment aussi (idÃ©alement un StatefulSet serait plus appropriÃ© pour une base, car il gÃ¨re mieux le stockage et le naming, mais Ã§a complexifie peu inutilement lâ€™exemple) :
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8
        env:
        - name: MYSQL_DATABASE
          value: "myappdb"
        - name: MYSQL_ROOT_PASSWORD
          value: "example"
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: mysql-data
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-data
        emptyDir: {}
```

Ici on dÃ©ploie MySQL (1 replica). On utilise un volume `emptyDir` pour le stockage de /var/lib/mysql â€“ **attention** : emptyDir est Ã©phÃ©mÃ¨re (liÃ© Ã  la vie du Pod). En production rÃ©elle, il faudrait un PersistentVolumeClaim pour que les donnÃ©es survivent Ã  un redÃ©ploiement du pod sur un autre nÅ“ud. Disons que pour un test, emptyDir suffit (mais retenez que ce nâ€™est pas persistant Ã  long terme : si le Pod bouge de nÅ“ud, les donnÃ©es sont perdues). On fournit les mÃªmes env de crÃ©ation de base et mdp root quâ€™avant.

Enfin, crÃ©ons les **Services** pour exposer ces deux Deployments (`k8s-services.yaml` par exemple) :
```yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  selector:
    app: mysql
  clusterIP: None
  ports:
    - port: 3306
      targetPort: 3306

---
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: NodePort
  selector:
    app: myapp
  ports:
    - port: 3000
      targetPort: 3000
      nodePort: 30000
```

Explications :
- Le Service **mysql** a un `clusterIP: None`. Ceci en fait un *Headless Service*, qui nâ€™attribue pas dâ€™IP stable mais permet la dÃ©couverte DNS *sans load balancing* (chaque pod a son DNS). Dans notre cas, comme il nâ€™y a quâ€™un pod MySQL, on aurait pu mettre un ClusterIP normal. Lâ€™important est que le nom "mysql" existe â€“ nos pods MyApp vont rÃ©soudre "mysql" et obtenir lâ€™IP du pod MySQL. On expose le port 3306. (ClusterIP None nâ€™est pas forcÃ©ment nÃ©cessaire, câ€™est une variante pour DB stateful).
- Le Service **myapp-service** est de type NodePort, ce qui permet un accÃ¨s externe. Il prend tous les pods avec label `app=myapp` (nos 2 pods Node.js) et Ã©coute sur port 3000, mappÃ© sur le port 3000 des pods. Le champ `nodePort: 30000` indique que sur chaque node du cluster, le port 30000 sera ouvert pour ce service. Ainsi, depuis lâ€™extÃ©rieur (supposant quâ€™on a lâ€™IP du node), on peut accÃ©der Ã  `<nodeIP>:30000` et Ã§a distribuera aux pods. Sur minikube, on ferait `minikube service myapp-service --url` pour obtenir lâ€™URL par exemple.

On peut appliquer ces manifests sur le cluster (minikube ou un vrai cluster) via :
```bash
kubectl apply -f k8s-mysql-deployment.yaml
kubectl apply -f k8s-myapp-deployment.yaml
kubectl apply -f k8s-services.yaml
```

Kubernetes va crÃ©er le tout. On peut surveiller avec `kubectl get pods -w` pour voir les pods se tÃ©lÃ©charger (il tÃ©lÃ©chargera lâ€™image `monutilisateur/monapp:1.0` depuis le registre) et dÃ©marrer. Une fois en statut *Running*, on teste lâ€™accÃ¨s :
- Depuis lâ€™intÃ©rieur du cluster : on pourrait exec dans le pod myapp et faire un curl sur localhost:3000 ou utiliser `kubectl port-forward service/myapp-service 3000:3000` pour accÃ©der en local.
- Depuis lâ€™extÃ©rieur (si cluster sur un VPS par ex) : taper `http://<IP-du-noeud>:30000`. Sur minikube, `minikube service myapp-service` ouvre directement le navigateur sur lâ€™URL correcte.

Notre application devrait rÃ©pondre, reliÃ©e Ã  son MySQL. On a donc rÃ©ussi le dÃ©ploiement sur Kubernetes ! ğŸ‰

**AmÃ©liorations et bonnes pratiques de ce dÃ©ploiement :**
- Comme dit, on utiliserait un *PersistentVolume* pour MySQL en prod afin de ne pas perdre les donnÃ©es si le pod bouge.
- On ajouterait probablement un Ingress Controller pour Ã©viter d'utiliser un NodePort (Ingress permet dâ€™exposer via une entrÃ©e HTTP/HTTPS plus Ã©lÃ©gamment, souvent combinÃ© avec un LoadBalancer sur le cloud).
- On sÃ©curiserait lâ€™accÃ¨s DB (utiliser un user applicatif au lieu de root, mettre le mot de passe dans un Secret Kubernetes plutÃ´t quâ€™en clair dans le dÃ©ploiement).
- On configurerait des *Liveness/Readiness Probes* sur le conteneur myapp (par ex, un endpoint `/health`) pour que Kubernetes sache quand le pod est prÃªt ou doit Ãªtre redÃ©marrÃ©.
- On pourrait ajuster le nombre de replicas myapp selon la charge, voire mettre un HPA.

MalgrÃ© ces simplifications, ce scÃ©nario montre le chemin parcouru :
- On a dÃ©veloppÃ© et testÃ© localement avec Compose, trÃ¨s proche de la config prod.
- On a construit une image Docker unique de l'app, quâ€™on a pu dÃ©ployer inchangÃ©e sur le cluster.
- En prod, Kubernetes gÃ¨re le redÃ©marrage automatique des conteneurs, lâ€™Ã©ventuelle mise Ã  lâ€™Ã©chelle (si on modifie `replicas`), et la robustesse (si un node tombe, on pourrait en avoir un autre).
- Si on veut dÃ©ployer une version 2.0 de lâ€™app, on construirait lâ€™image `monutilisateur/monapp:2.0`, on mettrait Ã  jour le Deployment (via `kubectl set image deployment/myapp-deployment myapp=monutilisateur/monapp:2.0` par exemple), et Kubernetes ferait le rolling update sans downtime.

Cette Ã©tude de cas, du code source jusquâ€™au dÃ©ploiement orchestrÃ©, illustre la puissance de Docker et Kubernetes pour un workflow moderne :
dÃ©veloppeurs et ops peuvent collaborer autour de fichiers de config (Dockerfile, docker-compose.yml, manifests Kubernetes) au lieu de manipulations manuelles. Lâ€™environnement est isolÃ© et reproductible, que ce soit sur la machine de dev, le serveur de staging ou le cluster de production.

**Projets pratiques pour aller plus loin :** 
- Tentez de conteneuriser une application existante (une appli Python Flask + Redis par ex.), dÃ©ployez-la avec Compose, puis sur Kubernetes (peut-Ãªtre en utilisant un Chart Helm pour apprendre un autre outil).
- Explorez des architectures multi-conteneurs plus complexes : par exemple, dÃ©ployer un stack MEAN (MongoDB, Express, Angular, Node) ou une appli 3 tiers (frontend, API, DB) en utilisant Docker Compose pour le dev et Kubernetes pour la prod.
- Mettez en place une pipeline CI/CD rÃ©elle : code sur GitHub, Actions qui build/push lâ€™image, et peut-Ãªtre un dÃ©ploiement auto sur un cluster Kubernetes de test (il existe des actions GitHub pour kubectl ou Helm).
- Testez la rÃ©silience : faites tomber un conteneur exprÃ¨s (`docker kill`) et voyez Docker le redÃ©marrer (si restart: always) ou Kubernetes recrÃ©er un pod, etc.
